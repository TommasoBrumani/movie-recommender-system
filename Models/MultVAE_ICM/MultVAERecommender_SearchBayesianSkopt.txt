SearchBayesianSkopt: Resuming 'MultVAERecommender' Failed, no such file exists.
SearchBayesianSkopt: Resuming 'MultVAERecommender' Failed, no such file exists.
SearchBayesianSkopt: New best config found. Config 0: {'epochs': 23, 'learning_rate': 0.00018501479614890847, 'l2_reg': 0.009026820672020194, 'dropout': 0.17033114260487428, 'total_anneal_steps': 535717, 'anneal_cap': 0.0362905802680732, 'batch_size': 1024, 'encoding_size': 109, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1872417, PRECISION_RECALL_MIN_DEN: 0.1885178, RECALL: 0.0391608, MAP: 0.0917340, MAP_MIN_DEN: 0.0924316, MRR: 0.4240959, NDCG: 0.2007247, F1: 0.0647743, HIT_RATE: 0.8313059, ARHR_ALL_HITS: 0.6198922, NOVELTY: 0.0051403, AVERAGE_POPULARITY: 0.7615749, DIVERSITY_MEAN_INTER_LIST: 0.5034706, DIVERSITY_HERFINDAHL: 0.9503434, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9997070, COVERAGE_USER_CORRECT: 0.8310623, DIVERSITY_GINI: 0.0010675, SHANNON_ENTROPY: 4.4614239, RATIO_DIVERSITY_HERFINDAHL: 0.9506991, RATIO_DIVERSITY_GINI: 0.0040996, RATIO_SHANNON_ENTROPY: 0.3583515, RATIO_AVERAGE_POPULARITY: 3.8527145, RATIO_NOVELTY: 0.0302805, 
SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 23, 'learning_rate': 0.00018501479614890847, 'l2_reg': 0.009026820672020194, 'dropout': 0.17033114260487428, 'total_anneal_steps': 535717, 'anneal_cap': 0.0362905802680732, 'batch_size': 1024, 'encoding_size': 109, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.2343816, PRECISION_RECALL_MIN_DEN: 0.2355139, RECALL: 0.0393352, MAP: 0.1242977, MAP_MIN_DEN: 0.1249077, MRR: 0.5002624, NDCG: 0.2517628, F1: 0.0673648, HIT_RATE: 0.8827799, ARHR_ALL_HITS: 0.7811452, NOVELTY: 0.0051403, AVERAGE_POPULARITY: 0.7615599, DIVERSITY_MEAN_INTER_LIST: 0.5035228, DIVERSITY_HERFINDAHL: 0.9503486, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.8821978, DIVERSITY_GINI: 0.0010676, SHANNON_ENTROPY: 4.4615412, RATIO_DIVERSITY_HERFINDAHL: 0.9507043, RATIO_DIVERSITY_GINI: 0.0041000, RATIO_SHANNON_ENTROPY: 0.3583610, RATIO_AVERAGE_POPULARITY: 3.8526385, RATIO_NOVELTY: 0.0302806, 

SearchBayesianSkopt: Config 1 Exception. Config: {'epochs': 300, 'learning_rate': 7.812829035615953e-05, 'l2_reg': 0.00033390825589665695, 'dropout': 0.44193635909973905, 'total_anneal_steps': 373886, 'anneal_cap': 0.41371117782688016, 'batch_size': 256, 'encoding_size': 15, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 192, in _train_with_early_stopping
    results_run, results_run_string = evaluator_object.evaluateRecommender(self)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Evaluation\Evaluator.py", line 271, in evaluateRecommender
    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Evaluation\Evaluator.py", line 481, in _run_evaluation_on_selected_users
    recommended_items_batch_list, scores_batch = recommender_object.recommend(test_user_batch_array,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 175, in recommend
    relevant_items_partition = (-scores_batch).argpartition(cutoff, axis=1)[:,0:cutoff]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 138. MiB for an array with shape (1000, 18059) and data type int64

SearchBayesianSkopt: Config 1 Exception. Config: {'epochs': 300, 'learning_rate': 0.00035127009739109214, 'l2_reg': 2.540967740649814e-06, 'dropout': 0.21057375009941173, 'total_anneal_steps': 290620, 'anneal_cap': 0.5250406940944045, 'batch_size': 128, 'encoding_size': 336, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1380, in _do_call
    return fn(*args)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1363, in _run_fn
    return self._call_tf_sessionrun(options, feed_dict, fetch_list,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1456, in _call_tf_sessionrun
    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_30_weight_q_0to1/Read/ReadVariableOp;0:0
	 [[{{node weight_q_0to1/Read/ReadVariableOp/_23}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[save_1/SaveV2/_32]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_30_weight_q_0to1/Read/ReadVariableOp;0:0
	 [[{{node weight_q_0to1/Read/ReadVariableOp/_23}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 328, in fit
    self._update_best_model()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 354, in _update_best_model
    self.save_model(self.temp_file_folder, file_name="_best_model", is_earlystopping_format = True)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 409, in save_model
    saver.save(self.sess, folder_path + file_name + "/session")
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 1276, in save
    model_checkpoint_path = sess.run(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 970, in run
    result = self._run(None, fetches, feed_dict, options_ptr,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1193, in _run
    results = self._do_run(handle, final_targets, final_fetches,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1373, in _do_run
    return self._do_call(_run_fn, feeds, fetches, targets, options,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1399, in _do_call
    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_30_weight_q_0to1/Read/ReadVariableOp;0:0
	 [[{{node weight_q_0to1/Read/ReadVariableOp/_23}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[save_1/SaveV2/_32]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_30_weight_q_0to1/Read/ReadVariableOp;0:0
	 [[{{node weight_q_0to1/Read/ReadVariableOp/_23}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored.

SearchBayesianSkopt: Config 2 Exception. Config: {'epochs': 300, 'learning_rate': 2.99795728745095e-06, 'l2_reg': 0.00011964127133797951, 'dropout': 0.18102745897700223, 'total_anneal_steps': 246570, 'anneal_cap': 0.4004189797329902, 'batch_size': 512, 'encoding_size': 375, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 3 Exception. Config: {'epochs': 300, 'learning_rate': 9.476403014045639e-05, 'l2_reg': 0.00021284090722968285, 'dropout': 0.3567067441725172, 'total_anneal_steps': 417275, 'anneal_cap': 0.14887245831675044, 'batch_size': 512, 'encoding_size': 447, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 4 Exception. Config: {'epochs': 300, 'learning_rate': 0.0006459931690244327, 'l2_reg': 1.4549736557816611e-05, 'dropout': 0.2655890685707052, 'total_anneal_steps': 490614, 'anneal_cap': 0.5191562548934143, 'batch_size': 256, 'encoding_size': 176, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 5 Exception. Config: {'epochs': 300, 'learning_rate': 3.878256829940745e-05, 'l2_reg': 1.5545861571675987e-05, 'dropout': 0.18402228790225317, 'total_anneal_steps': 444423, 'anneal_cap': 0.19734446624315385, 'batch_size': 256, 'encoding_size': 135, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 6 Exception. Config: {'epochs': 300, 'learning_rate': 0.00015855577001621014, 'l2_reg': 1.9018193334165677e-06, 'dropout': 0.46242437402207276, 'total_anneal_steps': 494705, 'anneal_cap': 0.1896169908145637, 'batch_size': 512, 'encoding_size': 288, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 7 Exception. Config: {'epochs': 300, 'learning_rate': 8.764923640738152e-06, 'l2_reg': 0.001862336529173182, 'dropout': 0.06121768286228965, 'total_anneal_steps': 456835, 'anneal_cap': 0.5081193405015718, 'batch_size': 256, 'encoding_size': 405, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 8 Exception. Config: {'epochs': 300, 'learning_rate': 7.318707494303183e-05, 'l2_reg': 8.89559052824682e-06, 'dropout': 0.006365521606915527, 'total_anneal_steps': 343608, 'anneal_cap': 0.19920049526870678, 'batch_size': 256, 'encoding_size': 404, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 9 Exception. Config: {'epochs': 300, 'learning_rate': 2.588929846996047e-05, 'l2_reg': 1.1950188329150976e-05, 'dropout': 0.2444704906507283, 'total_anneal_steps': 104103, 'anneal_cap': 0.2671594840715071, 'batch_size': 512, 'encoding_size': 346, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 10 Exception. Config: {'epochs': 300, 'learning_rate': 0.0001543657928161784, 'l2_reg': 1.1279369168659564e-06, 'dropout': 0.214428281100574, 'total_anneal_steps': 166368, 'anneal_cap': 0.194786790082759, 'batch_size': 256, 'encoding_size': 61, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 11 Exception. Config: {'epochs': 300, 'learning_rate': 0.0001395271781739768, 'l2_reg': 0.005793197645341765, 'dropout': 0.46306973195113205, 'total_anneal_steps': 205594, 'anneal_cap': 0.49883475603208693, 'batch_size': 512, 'encoding_size': 430, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 12 Exception. Config: {'epochs': 300, 'learning_rate': 0.0011043001303995912, 'l2_reg': 0.006721027158122493, 'dropout': 0.21320617993547886, 'total_anneal_steps': 347544, 'anneal_cap': 0.4016149620605637, 'batch_size': 256, 'encoding_size': 390, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 13 Exception. Config: {'epochs': 300, 'learning_rate': 9.853247889031037e-06, 'l2_reg': 0.001250211487800379, 'dropout': 0.6707670471493782, 'total_anneal_steps': 509321, 'anneal_cap': 0.4457825974990952, 'batch_size': 512, 'encoding_size': 75, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 14 Exception. Config: {'epochs': 300, 'learning_rate': 0.00012121166434262813, 'l2_reg': 1.4820488925261043e-05, 'dropout': 0.5303844423193323, 'total_anneal_steps': 164007, 'anneal_cap': 0.23051732698636562, 'batch_size': 512, 'encoding_size': 98, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 15 Exception. Config: {'epochs': 300, 'learning_rate': 4.1190083822326816e-05, 'l2_reg': 1.821819068511624e-05, 'dropout': 0.680905859518967, 'total_anneal_steps': 441360, 'anneal_cap': 0.5275799075591696, 'batch_size': 128, 'encoding_size': 243, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 16 Exception. Config: {'epochs': 300, 'learning_rate': 9.847004105858442e-06, 'l2_reg': 4.7161609697795605e-05, 'dropout': 0.3187842223660091, 'total_anneal_steps': 177095, 'anneal_cap': 0.22903358734704604, 'batch_size': 512, 'encoding_size': 266, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 17 Exception. Config: {'epochs': 300, 'learning_rate': 0.0003710371329721094, 'l2_reg': 2.5507986816976587e-06, 'dropout': 0.18147389122984856, 'total_anneal_steps': 240614, 'anneal_cap': 0.3873805373786929, 'batch_size': 512, 'encoding_size': 115, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 18 Exception. Config: {'epochs': 300, 'learning_rate': 0.001553347353488432, 'l2_reg': 1.6178823677569701e-06, 'dropout': 0.474537636375614, 'total_anneal_steps': 151423, 'anneal_cap': 0.5052448470404959, 'batch_size': 512, 'encoding_size': 170, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 520, in _with_data
    return coo_matrix((data, (self.row.copy(), self.col.copy())),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: New best config found. Config 1: {'epochs': 6, 'learning_rate': 0.0009052797483310936, 'l2_reg': 4.4256850761986106e-05, 'dropout': 0.396318312208681, 'total_anneal_steps': 429543, 'anneal_cap': 0.04079816933864041, 'batch_size': 128, 'encoding_size': 438, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2179072, PRECISION_RECALL_MIN_DEN: 0.2196492, RECALL: 0.0502603, MAP: 0.1030031, MAP_MIN_DEN: 0.1038483, MRR: 0.4382083, NDCG: 0.2247476, F1: 0.0816809, HIT_RATE: 0.8961648, ARHR_ALL_HITS: 0.6702900, NOVELTY: 0.0057905, AVERAGE_POPULARITY: 0.4604160, DIVERSITY_MEAN_INTER_LIST: 0.9328287, DIVERSITY_HERFINDAHL: 0.9932760, COVERAGE_ITEM: 0.2065452, COVERAGE_ITEM_CORRECT: 0.1128523, COVERAGE_USER: 0.9990476, COVERAGE_USER_CORRECT: 0.8953114, DIVERSITY_GINI: 0.0283548, SHANNON_ENTROPY: 8.8360211, RATIO_DIVERSITY_HERFINDAHL: 0.9936476, RATIO_DIVERSITY_GINI: 0.1088073, RATIO_SHANNON_ENTROPY: 0.7096754, RATIO_AVERAGE_POPULARITY: 2.3133368, RATIO_NOVELTY: 0.0341083, 
SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 6, 'learning_rate': 0.0009052797483310936, 'l2_reg': 4.4256850761986106e-05, 'dropout': 0.396318312208681, 'total_anneal_steps': 429543, 'anneal_cap': 0.04079816933864041, 'batch_size': 128, 'encoding_size': 438, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.2723407, PRECISION_RECALL_MIN_DEN: 0.2738188, RECALL: 0.0506861, MAP: 0.1397463, MAP_MIN_DEN: 0.1404585, MRR: 0.5069880, NDCG: 0.2801723, F1: 0.0854659, HIT_RATE: 0.9372480, ARHR_ALL_HITS: 0.8364347, NOVELTY: 0.0057904, AVERAGE_POPULARITY: 0.4604936, DIVERSITY_MEAN_INTER_LIST: 0.9327696, DIVERSITY_HERFINDAHL: 0.9932701, COVERAGE_ITEM: 0.2065452, COVERAGE_ITEM_CORRECT: 0.1196633, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.9366300, DIVERSITY_GINI: 0.0283483, SHANNON_ENTROPY: 8.8353104, RATIO_DIVERSITY_HERFINDAHL: 0.9936417, RATIO_DIVERSITY_GINI: 0.1087824, RATIO_SHANNON_ENTROPY: 0.7096184, RATIO_AVERAGE_POPULARITY: 2.3137267, RATIO_NOVELTY: 0.0341075, 

SearchBayesianSkopt: Config 2 is suboptimal. Config: {'epochs': 11, 'learning_rate': 0.0042562813151952, 'l2_reg': 0.003434784562260893, 'dropout': 0.049508830774611046, 'total_anneal_steps': 540532, 'anneal_cap': 0.0085471337677713, 'batch_size': 128, 'encoding_size': 361, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2062257, PRECISION_RECALL_MIN_DEN: 0.2076340, RECALL: 0.0448062, MAP: 0.0997072, MAP_MIN_DEN: 0.1003962, MRR: 0.4377577, NDCG: 0.2167604, F1: 0.0736177, HIT_RATE: 0.8713060, ARHR_ALL_HITS: 0.6582929, NOVELTY: 0.0054124, AVERAGE_POPULARITY: 0.6209923, DIVERSITY_MEAN_INTER_LIST: 0.7757427, DIVERSITY_HERFINDAHL: 0.9775686, COVERAGE_ITEM: 0.0348303, COVERAGE_ITEM_CORRECT: 0.0262473, COVERAGE_USER: 0.9990476, COVERAGE_USER_CORRECT: 0.8704762, DIVERSITY_GINI: 0.0040087, SHANNON_ENTROPY: 6.3910063, RATIO_DIVERSITY_HERFINDAHL: 0.9779343, RATIO_DIVERSITY_GINI: 0.0153829, RATIO_SHANNON_ENTROPY: 0.5133012, RATIO_AVERAGE_POPULARITY: 3.1201446, RATIO_NOVELTY: 0.0318812, 
SearchBayesianSkopt: New best config found. Config 19: {'epochs': 36, 'learning_rate': 4.483870544358322e-06, 'l2_reg': 1.2272971039342996e-05, 'dropout': 0.18770714863928314, 'total_anneal_steps': 565573, 'anneal_cap': 0.27373832265898074, 'batch_size': 512, 'encoding_size': 192, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1883665, PRECISION_RECALL_MIN_DEN: 0.1896995, RECALL: 0.0394532, MAP: 0.0919808, MAP_MIN_DEN: 0.0928210, MRR: 0.4282151, NDCG: 0.2020872, F1: 0.0652417, HIT_RATE: 0.8339324, ARHR_ALL_HITS: 0.6239621, NOVELTY: 0.0051410, AVERAGE_POPULARITY: 0.7585451, DIVERSITY_MEAN_INTER_LIST: 0.5048082, DIVERSITY_HERFINDAHL: 0.9504771, COVERAGE_ITEM: 0.0022703, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8328938, DIVERSITY_GINI: 0.0010708, SHANNON_ENTROPY: 4.4642345, RATIO_DIVERSITY_HERFINDAHL: 0.9508329, RATIO_DIVERSITY_GINI: 0.0041119, RATIO_SHANNON_ENTROPY: 0.3585797, RATIO_AVERAGE_POPULARITY: 3.8489877, RATIO_NOVELTY: 0.0302851, 
SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 36, 'learning_rate': 4.483870544358322e-06, 'l2_reg': 1.2272971039342996e-05, 'dropout': 0.18770714863928314, 'total_anneal_steps': 565573, 'anneal_cap': 0.27373832265898074, 'batch_size': 512, 'encoding_size': 192, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.2340737, PRECISION_RECALL_MIN_DEN: 0.2352727, RECALL: 0.0394597, MAP: 0.1235838, MAP_MIN_DEN: 0.1241955, MRR: 0.4993097, NDCG: 0.2510881, F1: 0.0675346, HIT_RATE: 0.8854190, ARHR_ALL_HITS: 0.7780598, NOVELTY: 0.0051410, AVERAGE_POPULARITY: 0.7585582, DIVERSITY_MEAN_INTER_LIST: 0.5047199, DIVERSITY_HERFINDAHL: 0.9504683, COVERAGE_ITEM: 0.0022703, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.8848352, DIVERSITY_GINI: 0.0010706, SHANNON_ENTROPY: 4.4640407, RATIO_DIVERSITY_HERFINDAHL: 0.9508241, RATIO_DIVERSITY_GINI: 0.0041111, RATIO_SHANNON_ENTROPY: 0.3585641, RATIO_AVERAGE_POPULARITY: 3.8490539, RATIO_NOVELTY: 0.0302850, 

SearchBayesianSkopt: New best config found. Config 3: {'epochs': 26, 'learning_rate': 0.00023953486111899532, 'l2_reg': 0.003472363448694099, 'dropout': 0.2712701174464813, 'total_anneal_steps': 233655, 'anneal_cap': 0.5217373161830644, 'batch_size': 256, 'encoding_size': 118, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2172472, PRECISION_RECALL_MIN_DEN: 0.2187298, RECALL: 0.0475777, MAP: 0.1055038, MAP_MIN_DEN: 0.1062416, MRR: 0.4487134, NDCG: 0.2266795, F1: 0.0780601, HIT_RATE: 0.8881719, ARHR_ALL_HITS: 0.6842426, NOVELTY: 0.0054512, AVERAGE_POPULARITY: 0.6051567, DIVERSITY_MEAN_INTER_LIST: 0.8265767, DIVERSITY_HERFINDAHL: 0.9826516, COVERAGE_ITEM: 0.0440777, COVERAGE_ITEM_CORRECT: 0.0311756, COVERAGE_USER: 0.9990476, COVERAGE_USER_CORRECT: 0.8873260, DIVERSITY_GINI: 0.0057160, SHANNON_ENTROPY: 6.8754791, RATIO_DIVERSITY_HERFINDAHL: 0.9830193, RATIO_DIVERSITY_GINI: 0.0219344, RATIO_SHANNON_ENTROPY: 0.5522122, RATIO_AVERAGE_POPULARITY: 3.0405795, RATIO_NOVELTY: 0.0321097, 
SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 26, 'learning_rate': 0.00023953486111899532, 'l2_reg': 0.003472363448694099, 'dropout': 0.2712701174464813, 'total_anneal_steps': 233655, 'anneal_cap': 0.5217373161830644, 'batch_size': 256, 'encoding_size': 118, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.2703981, PRECISION_RECALL_MIN_DEN: 0.2717131, RECALL: 0.0478489, MAP: 0.1417159, MAP_MIN_DEN: 0.1423937, MRR: 0.5134788, NDCG: 0.2809554, F1: 0.0813095, HIT_RATE: 0.9285976, ARHR_ALL_HITS: 0.8467229, NOVELTY: 0.0054512, AVERAGE_POPULARITY: 0.6051692, DIVERSITY_MEAN_INTER_LIST: 0.8265232, DIVERSITY_HERFINDAHL: 0.9826463, COVERAGE_ITEM: 0.0440777, COVERAGE_ITEM_CORRECT: 0.0328922, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.9279853, DIVERSITY_GINI: 0.0057152, SHANNON_ENTROPY: 6.8751860, RATIO_DIVERSITY_HERFINDAHL: 0.9830139, RATIO_DIVERSITY_GINI: 0.0219314, RATIO_SHANNON_ENTROPY: 0.5521887, RATIO_AVERAGE_POPULARITY: 3.0406423, RATIO_NOVELTY: 0.0321098, 

SearchBayesianSkopt: Config 1 Exception. Config: {'epochs': 300, 'learning_rate': 1.3785243033851594e-06, 'l2_reg': 0.006420297350314424, 'dropout': 0.6720055865514049, 'total_anneal_steps': 263945, 'anneal_cap': 0.35317826628993226, 'batch_size': 512, 'encoding_size': 132, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 192, in _train_with_early_stopping
    results_run, results_run_string = evaluator_object.evaluateRecommender(self)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Evaluation\Evaluator.py", line 271, in evaluateRecommender
    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Evaluation\Evaluator.py", line 481, in _run_evaluation_on_selected_users
    recommended_items_batch_list, scores_batch = recommender_object.recommend(test_user_batch_array,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 175, in recommend
    relevant_items_partition = (-scores_batch).argpartition(cutoff, axis=1)[:,0:cutoff]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 138. MiB for an array with shape (1000, 18059) and data type int64

SearchBayesianSkopt: Config 4 Exception. Config: {'epochs': 300, 'learning_rate': 1.660541312874489e-05, 'l2_reg': 0.004300109864702585, 'dropout': 0.36368036316462365, 'total_anneal_steps': 575683, 'anneal_cap': 0.44146075046671124, 'batch_size': 256, 'encoding_size': 314, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 192, in _train_with_early_stopping
    results_run, results_run_string = evaluator_object.evaluateRecommender(self)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Evaluation\Evaluator.py", line 271, in evaluateRecommender
    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Evaluation\Evaluator.py", line 481, in _run_evaluation_on_selected_users
    recommended_items_batch_list, scores_batch = recommender_object.recommend(test_user_batch_array,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 175, in recommend
    relevant_items_partition = (-scores_batch).argpartition(cutoff, axis=1)[:,0:cutoff]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 138. MiB for an array with shape (1000, 18059) and data type int64

SearchBayesianSkopt: Config 20 Exception. Config: {'epochs': 300, 'learning_rate': 1.765307934878554e-06, 'l2_reg': 0.0026848564541783167, 'dropout': 0.323645431644515, 'total_anneal_steps': 160050, 'anneal_cap': 0.5029927736036114, 'batch_size': 512, 'encoding_size': 72, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 177, in _train_with_early_stopping
    self._run_epoch(epochs_current)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 371, in _run_epoch
    X = X.astype('float32')
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.3 MiB for an array with shape (512, 18059) and data type float32

SearchBayesianSkopt: Config 21 Exception. Config: {'epochs': 300, 'learning_rate': 2.600297261783478e-05, 'l2_reg': 0.002226622745718308, 'dropout': 0.13738585213299903, 'total_anneal_steps': 366856, 'anneal_cap': 0.3831490842456622, 'batch_size': 128, 'encoding_size': 319, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1380, in _do_call
    return fn(*args)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1363, in _run_fn
    return self._call_tf_sessionrun(options, feed_dict, fetch_list,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1456, in _call_tf_sessionrun
    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_70_weight_p_2to3/Adam/Read/ReadVariableOp;0:0
	 [[{{node weight_p_2to3/Adam/Read/ReadVariableOp/_55}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[save_1/SaveV2/_80]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_70_weight_p_2to3/Adam/Read/ReadVariableOp;0:0
	 [[{{node weight_p_2to3/Adam/Read/ReadVariableOp/_55}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 328, in fit
    self._update_best_model()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 354, in _update_best_model
    self.save_model(self.temp_file_folder, file_name="_best_model", is_earlystopping_format = True)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 409, in save_model
    saver.save(self.sess, folder_path + file_name + "/session")
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 1276, in save
    model_checkpoint_path = sess.run(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 970, in run
    result = self._run(None, fetches, feed_dict, options_ptr,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1193, in _run
    results = self._do_run(handle, final_targets, final_fetches,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1373, in _do_run
    return self._do_call(_run_fn, feeds, fetches, targets, options,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1399, in _do_call
    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_70_weight_p_2to3/Adam/Read/ReadVariableOp;0:0
	 [[{{node weight_p_2to3/Adam/Read/ReadVariableOp/_55}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[save_1/SaveV2/_80]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_70_weight_p_2to3/Adam/Read/ReadVariableOp;0:0
	 [[{{node weight_p_2to3/Adam/Read/ReadVariableOp/_55}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored.

SearchBayesianSkopt: Config 22 Exception. Config: {'epochs': 300, 'learning_rate': 0.0020133509293286194, 'l2_reg': 4.614231463786222e-05, 'dropout': 0.44924294411008064, 'total_anneal_steps': 307838, 'anneal_cap': 0.4564973914421555, 'batch_size': 256, 'encoding_size': 396, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type float32

SearchBayesianSkopt: Config 23 Exception. Config: {'epochs': 300, 'learning_rate': 2.1845051860350122e-05, 'l2_reg': 0.00016934690783587658, 'dropout': 0.4834531006299975, 'total_anneal_steps': 296367, 'anneal_cap': 0.07183574970493672, 'batch_size': 512, 'encoding_size': 232, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Recommender_utils.py", line 29, in check_matrix
    return X.tocsr().astype(dtype)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\coo.py", line 404, in tocsr
    data = np.empty_like(self.data, dtype=upcast(self.dtype))
  File "<__array_function__ internals>", line 5, in empty_like
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type float32

SearchBayesianSkopt: Config 24 Exception. Config: {'epochs': 300, 'learning_rate': 1.2093323468222998e-06, 'l2_reg': 0.009877845086952195, 'dropout': 0.1769781228077308, 'total_anneal_steps': 599563, 'anneal_cap': 0.5996460344974303, 'batch_size': 1024, 'encoding_size': 228, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Recommender_utils.py", line 29, in check_matrix
    return X.tocsr().astype(dtype)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 75, in astype
    return self.copy()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type float32

SearchBayesianSkopt: Config 2 Exception. Config: {'epochs': 300, 'learning_rate': 3.690548318954737e-05, 'l2_reg': 0.0001079612369836418, 'dropout': 0.07528674171046108, 'total_anneal_steps': 471736, 'anneal_cap': 0.2547154487709955, 'batch_size': 128, 'encoding_size': 186, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 177, in _train_with_early_stopping
    self._run_epoch(epochs_current)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 370, in _run_epoch
    X = X.toarray()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\compressed.py", line 1031, in toarray
    out = self._process_toarray_args(order, out)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\base.py", line 1202, in _process_toarray_args
    return np.zeros(self.shape, dtype=self.dtype, order=order)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.82 MiB for an array with shape (128, 18059) and data type float32

SearchBayesianSkopt: Config 3 Exception. Config: {'epochs': 300, 'learning_rate': 6.643640490506753e-06, 'l2_reg': 0.0010966165587311984, 'dropout': 0.6767250483190862, 'total_anneal_steps': 287762, 'anneal_cap': 0.29957652844808136, 'batch_size': 1024, 'encoding_size': 393, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Recommender_utils.py", line 29, in check_matrix
    return X.tocsr().astype(dtype)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 75, in astype
    return self.copy()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\compressed.py", line 1210, in _with_data
    return self.__class__((data, self.indices.copy(),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 4 Exception. Config: {'epochs': 300, 'learning_rate': 9.011704250693785e-06, 'l2_reg': 0.00277283678955196, 'dropout': 0.025629769613590276, 'total_anneal_steps': 397131, 'anneal_cap': 0.39121419105945954, 'batch_size': 512, 'encoding_size': 192, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Recommender_utils.py", line 29, in check_matrix
    return X.tocsr().astype(dtype)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 75, in astype
    return self.copy()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\compressed.py", line 1210, in _with_data
    return self.__class__((data, self.indices.copy(),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 5 Exception. Config: {'epochs': 300, 'learning_rate': 1.0980910730382e-06, 'l2_reg': 3.8097247844022973e-06, 'dropout': 0.017417265734372748, 'total_anneal_steps': 363812, 'anneal_cap': 0.2995405167278748, 'batch_size': 512, 'encoding_size': 357, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 177, in _train_with_early_stopping
    self._run_epoch(epochs_current)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 370, in _run_epoch
    X = X.toarray()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\compressed.py", line 1031, in toarray
    out = self._process_toarray_args(order, out)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\base.py", line 1202, in _process_toarray_args
    return np.zeros(self.shape, dtype=self.dtype, order=order)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.3 MiB for an array with shape (512, 18059) and data type float32

SearchBayesianSkopt: Config 6 Exception. Config: {'epochs': 300, 'learning_rate': 3.452917846887388e-06, 'l2_reg': 7.975067938191607e-05, 'dropout': 0.5512299961427634, 'total_anneal_steps': 523795, 'anneal_cap': 0.009354555554790502, 'batch_size': 256, 'encoding_size': 213, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Recommender_utils.py", line 29, in check_matrix
    return X.tocsr().astype(dtype)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 75, in astype
    return self.copy()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\compressed.py", line 1210, in _with_data
    return self.__class__((data, self.indices.copy(),
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type int32

SearchBayesianSkopt: Config 7 Exception. Config: {'epochs': 300, 'learning_rate': 3.4545644776054104e-05, 'l2_reg': 1.5256551665339003e-05, 'dropout': 0.7089931922892103, 'total_anneal_steps': 417903, 'anneal_cap': 0.17983089144154613, 'batch_size': 128, 'encoding_size': 15, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 301, in _fit_model
    recommender_instance = self.recommender_class(*self.recommender_input_args.CONSTRUCTOR_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 240, in __init__
    super(MultVAERecommender, self).__init__(URM_train)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\BaseRecommender.py", line 22, in __init__
    self.URM_train = check_matrix(URM_train.copy(), 'csr', dtype=np.float32)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\scipy\sparse\data.py", line 92, in copy
    return self._with_data(self.data.copy(), copy=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 13.1 MiB for an array with shape (3443392,) and data type float32

SearchBayesianSkopt: Config 7 is suboptimal. Config: {'epochs': 13, 'learning_rate': 9.745266856157992e-05, 'l2_reg': 6.790560203882886e-06, 'dropout': 0.4134133818056763, 'total_anneal_steps': 240785, 'anneal_cap': 0.3187420598950976, 'batch_size': 1024, 'encoding_size': 478, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1867761, PRECISION_RECALL_MIN_DEN: 0.1883238, RECALL: 0.0393974, MAP: 0.0917419, MAP_MIN_DEN: 0.0926679, MRR: 0.4263246, NDCG: 0.2011408, F1: 0.0650695, HIT_RATE: 0.8292772, ARHR_ALL_HITS: 0.6222281, NOVELTY: 0.0051399, AVERAGE_POPULARITY: 0.7639281, DIVERSITY_MEAN_INTER_LIST: 0.5047195, DIVERSITY_HERFINDAHL: 0.9504683, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9994139, COVERAGE_USER_CORRECT: 0.8287912, DIVERSITY_GINI: 0.0010717, SHANNON_ENTROPY: 4.4651471, RATIO_DIVERSITY_HERFINDAHL: 0.9508241, RATIO_DIVERSITY_GINI: 0.0041147, RATIO_SHANNON_ENTROPY: 0.3586488, RATIO_AVERAGE_POPULARITY: 3.8550314, RATIO_NOVELTY: 0.0302781, 
SearchBayesianSkopt: Config 7 is suboptimal. Config: {'epochs': 30, 'learning_rate': 0.0007237215901568581, 'l2_reg': 0.004105520552297538, 'dropout': 0.06325420452505331, 'total_anneal_steps': 591571, 'anneal_cap': 0.3298542871478575, 'batch_size': 512, 'encoding_size': 26, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2116910, PRECISION_RECALL_MIN_DEN: 0.2134870, RECALL: 0.0461189, MAP: 0.1027545, MAP_MIN_DEN: 0.1037774, MRR: 0.4393880, NDCG: 0.2216002, F1: 0.0757376, HIT_RATE: 0.8741479, ARHR_ALL_HITS: 0.6688520, NOVELTY: 0.0053319, AVERAGE_POPULARITY: 0.6581993, DIVERSITY_MEAN_INTER_LIST: 0.7659297, DIVERSITY_HERFINDAHL: 0.9765874, COVERAGE_ITEM: 0.0278531, COVERAGE_ITEM_CORRECT: 0.0210975, COVERAGE_USER: 0.9994872, COVERAGE_USER_CORRECT: 0.8736996, DIVERSITY_GINI: 0.0034315, SHANNON_ENTROPY: 6.2141301, RATIO_DIVERSITY_HERFINDAHL: 0.9769533, RATIO_DIVERSITY_GINI: 0.0131795, RATIO_SHANNON_ENTROPY: 0.4991538, RATIO_AVERAGE_POPULARITY: 3.3174924, RATIO_NOVELTY: 0.0314103, 
SearchBayesianSkopt: New best config found. Config 8: {'epochs': 78, 'learning_rate': 0.00020012282688153856, 'l2_reg': 0.00010434091489008437, 'dropout': 0.09398173291337629, 'total_anneal_steps': 150629, 'anneal_cap': 0.47359130849447373, 'batch_size': 512, 'encoding_size': 322, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2161035, PRECISION_RECALL_MIN_DEN: 0.2179724, RECALL: 0.0470617, MAP: 0.1057621, MAP_MIN_DEN: 0.1068083, MRR: 0.4518105, NDCG: 0.2270024, F1: 0.0772914, HIT_RATE: 0.8786924, ARHR_ALL_HITS: 0.6874979, NOVELTY: 0.0053352, AVERAGE_POPULARITY: 0.6563190, DIVERSITY_MEAN_INTER_LIST: 0.7778841, DIVERSITY_HERFINDAHL: 0.9777827, COVERAGE_ITEM: 0.0362700, COVERAGE_ITEM_CORRECT: 0.0275763, COVERAGE_USER: 0.9994872, COVERAGE_USER_CORRECT: 0.8782418, DIVERSITY_GINI: 0.0040213, SHANNON_ENTROPY: 6.3616439, RATIO_DIVERSITY_HERFINDAHL: 0.9781491, RATIO_DIVERSITY_GINI: 0.0154447, RATIO_SHANNON_ENTROPY: 0.5110030, RATIO_AVERAGE_POPULARITY: 3.3080154, RATIO_NOVELTY: 0.0314300, 
SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 78, 'learning_rate': 0.00020012282688153856, 'l2_reg': 0.00010434091489008437, 'dropout': 0.09398173291337629, 'total_anneal_steps': 150629, 'anneal_cap': 0.47359130849447373, 'batch_size': 512, 'encoding_size': 322, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.2723041, PRECISION_RECALL_MIN_DEN: 0.2735744, RECALL: 0.0475489, MAP: 0.1443874, MAP_MIN_DEN: 0.1450071, MRR: 0.5220508, NDCG: 0.2843853, F1: 0.0809607, HIT_RATE: 0.9255920, ARHR_ALL_HITS: 0.8611650, NOVELTY: 0.0053353, AVERAGE_POPULARITY: 0.6562938, DIVERSITY_MEAN_INTER_LIST: 0.7779402, DIVERSITY_HERFINDAHL: 0.9777883, COVERAGE_ITEM: 0.0362700, COVERAGE_ITEM_CORRECT: 0.0291268, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.9249817, DIVERSITY_GINI: 0.0040218, SHANNON_ENTROPY: 6.3619139, RATIO_DIVERSITY_HERFINDAHL: 0.9781547, RATIO_DIVERSITY_GINI: 0.0154467, RATIO_SHANNON_ENTROPY: 0.5110246, RATIO_AVERAGE_POPULARITY: 3.3078882, RATIO_NOVELTY: 0.0314303, 

SearchBayesianSkopt: Config 9 is suboptimal. Config: {'epochs': 300, 'learning_rate': 3.348430115253294e-06, 'l2_reg': 2.5738065655915136e-05, 'dropout': 0.6707399936223637, 'total_anneal_steps': 340586, 'anneal_cap': 0.5726503843474837, 'batch_size': 512, 'encoding_size': 148, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1817575, PRECISION_RECALL_MIN_DEN: 0.1830580, RECALL: 0.0380820, MAP: 0.0838964, MAP_MIN_DEN: 0.0842815, MRR: 0.3822144, NDCG: 0.1880732, F1: 0.0629704, HIT_RATE: 0.8190420, ARHR_ALL_HITS: 0.5637248, NOVELTY: 0.0051533, AVERAGE_POPULARITY: 0.7481412, DIVERSITY_MEAN_INTER_LIST: 0.5002803, DIVERSITY_HERFINDAHL: 0.9500244, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8180220, DIVERSITY_GINI: 0.0010578, SHANNON_ENTROPY: 4.4520459, RATIO_DIVERSITY_HERFINDAHL: 0.9503802, RATIO_DIVERSITY_GINI: 0.0040619, RATIO_SHANNON_ENTROPY: 0.3576039, RATIO_AVERAGE_POPULARITY: 3.7974719, RATIO_NOVELTY: 0.0303573, 
SearchBayesianSkopt: Config 10 is suboptimal. Config: {'epochs': 3, 'learning_rate': 0.008203321016113391, 'l2_reg': 2.4511846799818848e-06, 'dropout': 0.6377579988895573, 'total_anneal_steps': 499395, 'anneal_cap': 0.070916121056994, 'batch_size': 256, 'encoding_size': 137, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2020098, PRECISION_RECALL_MIN_DEN: 0.2037603, RECALL: 0.0465019, MAP: 0.0942731, MAP_MIN_DEN: 0.0951634, MRR: 0.4159606, NDCG: 0.2089915, F1: 0.0756008, HIT_RATE: 0.8681141, ARHR_ALL_HITS: 0.6244627, NOVELTY: 0.0058747, AVERAGE_POPULARITY: 0.4360515, DIVERSITY_MEAN_INTER_LIST: 0.9318932, DIVERSITY_HERFINDAHL: 0.9931825, COVERAGE_ITEM: 0.1706628, COVERAGE_ITEM_CORRECT: 0.0914226, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8670330, DIVERSITY_GINI: 0.0245930, SHANNON_ENTROPY: 8.7256434, RATIO_DIVERSITY_HERFINDAHL: 0.9935545, RATIO_DIVERSITY_GINI: 0.0944379, RATIO_SHANNON_ENTROPY: 0.7008742, RATIO_AVERAGE_POPULARITY: 2.2133434, RATIO_NOVELTY: 0.0346074, 
SearchBayesianSkopt: New best config found. Config 11: {'epochs': 39, 'learning_rate': 0.0010508248004955593, 'l2_reg': 0.0014957840327166376, 'dropout': 0.20547646005785639, 'total_anneal_steps': 373236, 'anneal_cap': 0.5945731525716483, 'batch_size': 256, 'encoding_size': 204, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2264359, PRECISION_RECALL_MIN_DEN: 0.2280416, RECALL: 0.0499627, MAP: 0.1109573, MAP_MIN_DEN: 0.1118271, MRR: 0.4571130, NDCG: 0.2356139, F1: 0.0818625, HIT_RATE: 0.8935671, ARHR_ALL_HITS: 0.7088207, NOVELTY: 0.0054901, AVERAGE_POPULARITY: 0.5745926, DIVERSITY_MEAN_INTER_LIST: 0.8575987, DIVERSITY_HERFINDAHL: 0.9857536, COVERAGE_ITEM: 0.0878232, COVERAGE_ITEM_CORRECT: 0.0586411, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8924542, DIVERSITY_GINI: 0.0103262, SHANNON_ENTROPY: 7.4703529, RATIO_DIVERSITY_HERFINDAHL: 0.9861228, RATIO_DIVERSITY_GINI: 0.0396530, RATIO_SHANNON_ENTROPY: 0.6000449, RATIO_AVERAGE_POPULARITY: 2.9165603, RATIO_NOVELTY: 0.0323417, 
SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 39, 'learning_rate': 0.0010508248004955593, 'l2_reg': 0.0014957840327166376, 'dropout': 0.20547646005785639, 'total_anneal_steps': 373236, 'anneal_cap': 0.5945731525716483, 'batch_size': 256, 'encoding_size': 204, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.2852943, PRECISION_RECALL_MIN_DEN: 0.2865641, RECALL: 0.0507449, MAP: 0.1518534, MAP_MIN_DEN: 0.1525033, MRR: 0.5271032, NDCG: 0.2953829, F1: 0.0861640, HIT_RATE: 0.9388608, ARHR_ALL_HITS: 0.8878027, NOVELTY: 0.0054899, AVERAGE_POPULARITY: 0.5747198, DIVERSITY_MEAN_INTER_LIST: 0.8574197, DIVERSITY_HERFINDAHL: 0.9857357, COVERAGE_ITEM: 0.0878232, COVERAGE_ITEM_CORRECT: 0.0633479, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.9382418, DIVERSITY_GINI: 0.0103206, SHANNON_ENTROPY: 7.4689722, RATIO_DIVERSITY_HERFINDAHL: 0.9861049, RATIO_DIVERSITY_GINI: 0.0396314, RATIO_SHANNON_ENTROPY: 0.5999340, RATIO_AVERAGE_POPULARITY: 2.9172061, RATIO_NOVELTY: 0.0323404, 

SearchBayesianSkopt: Config 12 is suboptimal. Config: {'epochs': 13, 'learning_rate': 0.007759360819519999, 'l2_reg': 0.009215806813127045, 'dropout': 0.7230077774688405, 'total_anneal_steps': 551079, 'anneal_cap': 0.07291314504753364, 'batch_size': 1024, 'encoding_size': 347, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2210592, PRECISION_RECALL_MIN_DEN: 0.2226527, RECALL: 0.0486829, MAP: 0.1076908, MAP_MIN_DEN: 0.1085729, MRR: 0.4509903, NDCG: 0.2304785, F1: 0.0797933, HIT_RATE: 0.8865253, ARHR_ALL_HITS: 0.6941847, NOVELTY: 0.0054111, AVERAGE_POPULARITY: 0.5987429, DIVERSITY_MEAN_INTER_LIST: 0.8502331, DIVERSITY_HERFINDAHL: 0.9850171, COVERAGE_ITEM: 0.0361593, COVERAGE_ITEM_CORRECT: 0.0270779, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8854212, DIVERSITY_GINI: 0.0056316, SHANNON_ENTROPY: 6.9455163, RATIO_DIVERSITY_HERFINDAHL: 0.9853861, RATIO_DIVERSITY_GINI: 0.0216254, RATIO_SHANNON_ENTROPY: 0.5578882, RATIO_AVERAGE_POPULARITY: 3.0391444, RATIO_NOVELTY: 0.0318760, 
SearchBayesianSkopt: Config 13 is suboptimal. Config: {'epochs': 5, 'learning_rate': 0.0035147044987138753, 'l2_reg': 0.008306021467293492, 'dropout': 0.5262653426563001, 'total_anneal_steps': 405796, 'anneal_cap': 0.27576676044477744, 'batch_size': 256, 'encoding_size': 191, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - results: PRECISION: 0.2136507, PRECISION_RECALL_MIN_DEN: 0.2153773, RECALL: 0.0486235, MAP: 0.1004483, MAP_MIN_DEN: 0.1013718, MRR: 0.4334129, NDCG: 0.2206375, F1: 0.0792183, HIT_RATE: 0.8873322, ARHR_ALL_HITS: 0.6580673, NOVELTY: 0.0056949, AVERAGE_POPULARITY: 0.4893609, DIVERSITY_MEAN_INTER_LIST: 0.9089385, DIVERSITY_HERFINDAHL: 0.9908872, COVERAGE_ITEM: 0.1050446, COVERAGE_ITEM_CORRECT: 0.0715986, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8862271, DIVERSITY_GINI: 0.0162794, SHANNON_ENTROPY: 8.2120220, RATIO_DIVERSITY_HERFINDAHL: 0.9912584, RATIO_DIVERSITY_GINI: 0.0625135, RATIO_SHANNON_ENTROPY: 0.6596183, RATIO_AVERAGE_POPULARITY: 2.4839349, RATIO_NOVELTY: 0.0335480, 
SearchBayesianSkopt: Config 14 is suboptimal. Config: {'epochs': 22, 'learning_rate': 0.0008659125115752965, 'l2_reg': 0.0006254594079552869, 'dropout': 0.6291094627961913, 'total_anneal_steps': 536964, 'anneal_cap': 0.3173426897536209, 'batch_size': 128, 'encoding_size': 398, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2295533, PRECISION_RECALL_MIN_DEN: 0.2314265, RECALL: 0.0528063, MAP: 0.1106781, MAP_MIN_DEN: 0.1116664, MRR: 0.4540920, NDCG: 0.2369656, F1: 0.0858612, HIT_RATE: 0.9057434, ARHR_ALL_HITS: 0.7070174, NOVELTY: 0.0057644, AVERAGE_POPULARITY: 0.4518239, DIVERSITY_MEAN_INTER_LIST: 0.9407075, DIVERSITY_HERFINDAHL: 0.9940638, COVERAGE_ITEM: 0.1591450, COVERAGE_ITEM_CORRECT: 0.1025527, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.9046154, DIVERSITY_GINI: 0.0259744, SHANNON_ENTROPY: 8.9047420, RATIO_DIVERSITY_HERFINDAHL: 0.9944362, RATIO_DIVERSITY_GINI: 0.0997425, RATIO_SHANNON_ENTROPY: 0.7152600, RATIO_AVERAGE_POPULARITY: 2.2934018, RATIO_NOVELTY: 0.0339574, 
SearchBayesianSkopt: Config 15 is suboptimal. Config: {'epochs': 75, 'learning_rate': 1.2691897387735375e-06, 'l2_reg': 0.00048621861653867196, 'dropout': 0.7475145001382043, 'total_anneal_steps': 188666, 'anneal_cap': 0.2696126777802259, 'batch_size': 512, 'encoding_size': 488, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1857111, PRECISION_RECALL_MIN_DEN: 0.1869673, RECALL: 0.0388416, MAP: 0.0904814, MAP_MIN_DEN: 0.0912324, MRR: 0.4210689, NDCG: 0.1989784, F1: 0.0642461, HIT_RATE: 0.8247634, ARHR_ALL_HITS: 0.6140686, NOVELTY: 0.0051391, AVERAGE_POPULARITY: 0.7597858, DIVERSITY_MEAN_INTER_LIST: 0.5086116, DIVERSITY_HERFINDAHL: 0.9508574, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8237363, DIVERSITY_GINI: 0.0010803, SHANNON_ENTROPY: 4.4790795, RATIO_DIVERSITY_HERFINDAHL: 0.9512136, RATIO_DIVERSITY_GINI: 0.0041486, RATIO_SHANNON_ENTROPY: 0.3597753, RATIO_AVERAGE_POPULARITY: 3.8565782, RATIO_NOVELTY: 0.0302741, 
SearchBayesianSkopt: Config 16 Exception. Config: {'epochs': 300, 'learning_rate': 3.1792976834675067e-06, 'l2_reg': 0.0025760370209300418, 'dropout': 0.28385571154262296, 'total_anneal_steps': 453065, 'anneal_cap': 0.4507426593180965, 'batch_size': 128, 'encoding_size': 350, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1380, in _do_call
    return fn(*args)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1363, in _run_fn
    return self._call_tf_sessionrun(options, feed_dict, fetch_list,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1456, in _call_tf_sessionrun
    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.
  (0) FAILED_PRECONDITION: Failed to rename: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001.tempstate11170723315997492495 to: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001 : The process cannot access the file because it is being used by another process.
; Broken pipe
	 [[{{node save_7/SaveV2}}]]
	 [[save_7/SaveV2/_304]]
  (1) FAILED_PRECONDITION: Failed to rename: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001.tempstate11170723315997492495 to: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001 : The process cannot access the file because it is being used by another process.
; Broken pipe
	 [[{{node save_7/SaveV2}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 210, in _train_with_early_stopping
    self._update_best_model()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 354, in _update_best_model
    self.save_model(self.temp_file_folder, file_name="_best_model", is_earlystopping_format = True)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 409, in save_model
    saver.save(self.sess, folder_path + file_name + "/session")
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 1295, in save
    raise exc
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 1276, in save
    model_checkpoint_path = sess.run(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 970, in run
    result = self._run(None, fetches, feed_dict, options_ptr,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1193, in _run
    results = self._do_run(handle, final_targets, final_fetches,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1373, in _do_run
    return self._do_call(_run_fn, feeds, fetches, targets, options,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1399, in _do_call
    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter
tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.
  (0) FAILED_PRECONDITION: Failed to rename: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001.tempstate11170723315997492495 to: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001 : The process cannot access the file because it is being used by another process.
; Broken pipe
	 [[node save_7/SaveV2
 (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:408)
]]
	 [[save_7/SaveV2/_304]]
  (1) FAILED_PRECONDITION: Failed to rename: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001.tempstate11170723315997492495 to: ./result_experiments/__Temp_MultVAERecommender_18500/_best_model/session.data-00000-of-00001 : The process cannot access the file because it is being used by another process.
; Broken pipe
	 [[node save_7/SaveV2
 (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:408)
]]
0 successful operations.
0 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node save_7/SaveV2:
In[0] save_7/Const:	
In[1] save_7/SaveV2/tensor_names:	
In[2] save_7/SaveV2/shape_and_slices:	
In[3] beta1_power/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:132)	
In[4] beta2_power/Read/ReadVariableOp:	
In[5] bias_p_1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:220)	
In[6] bias_p_1/Adam/Read/ReadVariableOp:	
In[7] bias_p_1/Adam_1/Read/ReadVariableOp:	
In[8] bias_q_1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:201)	
In[9] bias_q_1/Adam/Read/ReadVariableOp:	
In[10] bias_q_1/Adam_1/Read/ReadVariableOp:	
In[11] weight_p_0to1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:215)	
In[12] weight_p_0to1/Adam/Read/ReadVariableOp:	
In[13] weight_p_0to1/Adam_1/Read/ReadVariableOp:	
In[14] weight_q_0to1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:196)	
In[15] weight_q_0to1/Adam/Read/ReadVariableOp:	
In[16] weight_q_0to1/Adam_1/Read/ReadVariableOp:

Operation defined at: (most recent call last)
>>>   File "C:/Users/Andrea/Documents/GitHub/recsys-challenge-polimi-2021/main.py", line 13, in <module>
>>>     hyperparameter_tuning()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\hyperparameter_tuning.py", line 113, in hyperparameter_tuning
>>>     runHyperparameterSearch_Collaborative(recommender_class,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\run_hyperparameter_search.py", line 968, in runHyperparameterSearch_Collaborative
>>>     hyperparameterSearch.search(recommender_input_args,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 338, in search
>>>     self.result = gp_minimize(self._objective_function_list_input,
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\gp.py", line 259, in gp_minimize
>>>     return base_minimize(
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\base.py", line 299, in base_minimize
>>>     next_y = func(next_x)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 412, in _objective_function_list_input
>>>     result = self._objective_function(current_fit_hyperparameters_dict)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
>>>     result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
>>>     recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
>>>     recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
>>>     super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
>>>     self._train_with_early_stopping(epochs,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 210, in _train_with_early_stopping
>>>     self._update_best_model()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 354, in _update_best_model
>>>     self.save_model(self.temp_file_folder, file_name="_best_model", is_earlystopping_format = True)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 408, in save_model
>>>     saver = tf.compat.v1.train.Saver()
>>> 

Input Source operations connected to node save_7/SaveV2:
In[0] save_7/Const:	
In[1] save_7/SaveV2/tensor_names:	
In[2] save_7/SaveV2/shape_and_slices:	
In[3] beta1_power/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:132)	
In[4] beta2_power/Read/ReadVariableOp:	
In[5] bias_p_1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:220)	
In[6] bias_p_1/Adam/Read/ReadVariableOp:	
In[7] bias_p_1/Adam_1/Read/ReadVariableOp:	
In[8] bias_q_1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:201)	
In[9] bias_q_1/Adam/Read/ReadVariableOp:	
In[10] bias_q_1/Adam_1/Read/ReadVariableOp:	
In[11] weight_p_0to1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:215)	
In[12] weight_p_0to1/Adam/Read/ReadVariableOp:	
In[13] weight_p_0to1/Adam_1/Read/ReadVariableOp:	
In[14] weight_q_0to1/Read/ReadVariableOp (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:196)	
In[15] weight_q_0to1/Adam/Read/ReadVariableOp:	
In[16] weight_q_0to1/Adam_1/Read/ReadVariableOp:

Operation defined at: (most recent call last)
>>>   File "C:/Users/Andrea/Documents/GitHub/recsys-challenge-polimi-2021/main.py", line 13, in <module>
>>>     hyperparameter_tuning()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\hyperparameter_tuning.py", line 113, in hyperparameter_tuning
>>>     runHyperparameterSearch_Collaborative(recommender_class,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\run_hyperparameter_search.py", line 968, in runHyperparameterSearch_Collaborative
>>>     hyperparameterSearch.search(recommender_input_args,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 338, in search
>>>     self.result = gp_minimize(self._objective_function_list_input,
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\gp.py", line 259, in gp_minimize
>>>     return base_minimize(
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\base.py", line 299, in base_minimize
>>>     next_y = func(next_x)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 412, in _objective_function_list_input
>>>     result = self._objective_function(current_fit_hyperparameters_dict)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
>>>     result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
>>>     recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
>>>     recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
>>>     super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
>>>     self._train_with_early_stopping(epochs,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 210, in _train_with_early_stopping
>>>     self._update_best_model()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 354, in _update_best_model
>>>     self.save_model(self.temp_file_folder, file_name="_best_model", is_earlystopping_format = True)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 408, in save_model
>>>     saver = tf.compat.v1.train.Saver()
>>> 

Original stack trace for 'save_7/SaveV2':
  File "C:/Users/Andrea/Documents/GitHub/recsys-challenge-polimi-2021/main.py", line 13, in <module>
    hyperparameter_tuning()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\hyperparameter_tuning.py", line 113, in hyperparameter_tuning
    runHyperparameterSearch_Collaborative(recommender_class,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\run_hyperparameter_search.py", line 968, in runHyperparameterSearch_Collaborative
    hyperparameterSearch.search(recommender_input_args,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 338, in search
    self.result = gp_minimize(self._objective_function_list_input,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\gp.py", line 259, in gp_minimize
    return base_minimize(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\base.py", line 299, in base_minimize
    next_y = func(next_x)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 412, in _objective_function_list_input
    result = self._objective_function(current_fit_hyperparameters_dict)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 210, in _train_with_early_stopping
    self._update_best_model()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 354, in _update_best_model
    self.save_model(self.temp_file_folder, file_name="_best_model", is_earlystopping_format = True)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 408, in save_model
    saver = tf.compat.v1.train.Saver()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 923, in __init__
    self.build()
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 935, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 963, in _build
    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 531, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 223, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\training\saver.py", line 138, in save_op
    return io_ops.save_v2(filename_tensor, tensor_names, tensor_slices,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\ops\gen_io_ops.py", line 1712, in save_v2
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 744, in _apply_op_helper
    op = g._create_op_internal(op_type_name, inputs, dtypes=None,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\framework\ops.py", line 3697, in _create_op_internal
    ret = Operation(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\framework\ops.py", line 2101, in __init__
    self._traceback = tf_stack.extract_stack_for_node(self._c_op)


SearchBayesianSkopt: Config 17 is suboptimal. Config: {'epochs': 17, 'learning_rate': 1.461596183252231e-05, 'l2_reg': 2.9920637722990746e-06, 'dropout': 0.7882498858720067, 'total_anneal_steps': 428851, 'anneal_cap': 0.35004124118771135, 'batch_size': 256, 'encoding_size': 505, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1858065, PRECISION_RECALL_MIN_DEN: 0.1871040, RECALL: 0.0390670, MAP: 0.0904844, MAP_MIN_DEN: 0.0912426, MRR: 0.4209770, NDCG: 0.1990872, F1: 0.0645598, HIT_RATE: 0.8252769, ARHR_ALL_HITS: 0.6142419, NOVELTY: 0.0051473, AVERAGE_POPULARITY: 0.7578785, DIVERSITY_MEAN_INTER_LIST: 0.5166031, DIVERSITY_HERFINDAHL: 0.9516565, COVERAGE_ITEM: 0.0045960, COVERAGE_ITEM_CORRECT: 0.0023811, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8242491, DIVERSITY_GINI: 0.0010976, SHANNON_ENTROPY: 4.5123645, RATIO_DIVERSITY_HERFINDAHL: 0.9520130, RATIO_DIVERSITY_GINI: 0.0042147, RATIO_SHANNON_ENTROPY: 0.3624489, RATIO_AVERAGE_POPULARITY: 3.8468968, RATIO_NOVELTY: 0.0303224, 
SearchBayesianSkopt: Config 18 is suboptimal. Config: {'epochs': 3, 'learning_rate': 5.059319497817616e-05, 'l2_reg': 8.467309339289094e-06, 'dropout': 0.1618515195993443, 'total_anneal_steps': 412890, 'anneal_cap': 0.004184657280015714, 'batch_size': 256, 'encoding_size': 181, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1851170, PRECISION_RECALL_MIN_DEN: 0.1864220, RECALL: 0.0388994, MAP: 0.0900957, MAP_MIN_DEN: 0.0908556, MRR: 0.4209298, NDCG: 0.1984669, F1: 0.0642894, HIT_RATE: 0.8274774, ARHR_ALL_HITS: 0.6127138, NOVELTY: 0.0051402, AVERAGE_POPULARITY: 0.7589184, DIVERSITY_MEAN_INTER_LIST: 0.5067277, DIVERSITY_HERFINDAHL: 0.9506691, COVERAGE_ITEM: 0.0022703, COVERAGE_ITEM_CORRECT: 0.0020488, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8264469, DIVERSITY_GINI: 0.0010768, SHANNON_ENTROPY: 4.4718979, RATIO_DIVERSITY_HERFINDAHL: 0.9510252, RATIO_DIVERSITY_GINI: 0.0041351, RATIO_SHANNON_ENTROPY: 0.3591985, RATIO_AVERAGE_POPULARITY: 3.8521755, RATIO_NOVELTY: 0.0302802, 
SearchBayesianSkopt: Config 19 is suboptimal. Config: {'epochs': 300, 'learning_rate': 1.1016476156374634e-06, 'l2_reg': 6.357097818597615e-06, 'dropout': 0.19881316161771756, 'total_anneal_steps': 496939, 'anneal_cap': 0.3740669135538712, 'batch_size': 256, 'encoding_size': 419, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1716203, PRECISION_RECALL_MIN_DEN: 0.1727617, RECALL: 0.0353589, MAP: 0.0801905, MAP_MIN_DEN: 0.0805847, MRR: 0.3841771, NDCG: 0.1810196, F1: 0.0586369, HIT_RATE: 0.8015844, ARHR_ALL_HITS: 0.5522422, NOVELTY: 0.0051853, AVERAGE_POPULARITY: 0.7212833, DIVERSITY_MEAN_INTER_LIST: 0.4876568, DIVERSITY_HERFINDAHL: 0.9487621, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8005861, DIVERSITY_GINI: 0.0010297, SHANNON_ENTROPY: 4.4250254, RATIO_DIVERSITY_HERFINDAHL: 0.9491175, RATIO_DIVERSITY_GINI: 0.0039542, RATIO_SHANNON_ENTROPY: 0.3554335, RATIO_AVERAGE_POPULARITY: 3.6611445, RATIO_NOVELTY: 0.0305462, 
SearchBayesianSkopt: Config 20 is suboptimal. Config: {'epochs': 13, 'learning_rate': 0.00010356576715768234, 'l2_reg': 8.662773770046855e-06, 'dropout': 0.5760566628596299, 'total_anneal_steps': 281845, 'anneal_cap': 0.36214127488556297, 'batch_size': 512, 'encoding_size': 120, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1871708, PRECISION_RECALL_MIN_DEN: 0.1884834, RECALL: 0.0393692, MAP: 0.0911343, MAP_MIN_DEN: 0.0919100, MRR: 0.4229353, NDCG: 0.2004032, F1: 0.0650548, HIT_RATE: 0.8309250, ARHR_ALL_HITS: 0.6179510, NOVELTY: 0.0052106, AVERAGE_POPULARITY: 0.7286063, DIVERSITY_MEAN_INTER_LIST: 0.5682845, DIVERSITY_HERFINDAHL: 0.9568243, COVERAGE_ITEM: 0.0060358, COVERAGE_ITEM_CORRECT: 0.0047622, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8298901, DIVERSITY_GINI: 0.0012885, SHANNON_ENTROPY: 4.8510604, RATIO_DIVERSITY_HERFINDAHL: 0.9571827, RATIO_DIVERSITY_GINI: 0.0049480, RATIO_SHANNON_ENTROPY: 0.3896541, RATIO_AVERAGE_POPULARITY: 3.6983148, RATIO_NOVELTY: 0.0306952, 
SearchBayesianSkopt: Config 21 is suboptimal. Config: {'epochs': 70, 'learning_rate': 4.6437502752020505e-05, 'l2_reg': 0.0009418746902900281, 'dropout': 0.10257036440315298, 'total_anneal_steps': 397758, 'anneal_cap': 0.309625626322411, 'batch_size': 1024, 'encoding_size': 82, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1858065, PRECISION_RECALL_MIN_DEN: 0.1871420, RECALL: 0.0391419, MAP: 0.0901527, MAP_MIN_DEN: 0.0909234, MRR: 0.4194144, NDCG: 0.1986888, F1: 0.0646621, HIT_RATE: 0.8264505, ARHR_ALL_HITS: 0.6119695, NOVELTY: 0.0051383, AVERAGE_POPULARITY: 0.7605432, DIVERSITY_MEAN_INTER_LIST: 0.5049722, DIVERSITY_HERFINDAHL: 0.9504935, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8254212, DIVERSITY_GINI: 0.0010707, SHANNON_ENTROPY: 4.4642146, RATIO_DIVERSITY_HERFINDAHL: 0.9508496, RATIO_DIVERSITY_GINI: 0.0041115, RATIO_SHANNON_ENTROPY: 0.3585813, RATIO_AVERAGE_POPULARITY: 3.8604225, RATIO_NOVELTY: 0.0302690, 
SearchBayesianSkopt: Config 22 is suboptimal. Config: {'epochs': 26, 'learning_rate': 0.0035862657204738775, 'l2_reg': 0.000761040479971397, 'dropout': 0.03689256722473325, 'total_anneal_steps': 293828, 'anneal_cap': 0.4060413910046527, 'batch_size': 512, 'encoding_size': 17, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2088755, PRECISION_RECALL_MIN_DEN: 0.2102769, RECALL: 0.0443097, MAP: 0.1019963, MAP_MIN_DEN: 0.1027964, MRR: 0.4422646, NDCG: 0.2197934, F1: 0.0731103, HIT_RATE: 0.8644466, ARHR_ALL_HITS: 0.6680375, NOVELTY: 0.0052423, AVERAGE_POPULARITY: 0.7011955, DIVERSITY_MEAN_INTER_LIST: 0.6855478, DIVERSITY_HERFINDAHL: 0.9685497, COVERAGE_ITEM: 0.0284069, COVERAGE_ITEM_CORRECT: 0.0211529, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8633700, DIVERSITY_GINI: 0.0024823, SHANNON_ENTROPY: 5.6906176, RATIO_DIVERSITY_HERFINDAHL: 0.9689126, RATIO_DIVERSITY_GINI: 0.0095321, RATIO_SHANNON_ENTROPY: 0.4570903, RATIO_AVERAGE_POPULARITY: 3.5591811, RATIO_NOVELTY: 0.0308820, 
SearchBayesianSkopt: Config 23 is suboptimal. Config: {'epochs': 17, 'learning_rate': 0.002302331994424829, 'l2_reg': 0.0008948487359095421, 'dropout': 0.28928250005484, 'total_anneal_steps': 186402, 'anneal_cap': 0.23158820652287693, 'batch_size': 128, 'encoding_size': 360, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2292379, PRECISION_RECALL_MIN_DEN: 0.2310208, RECALL: 0.0518902, MAP: 0.1109544, MAP_MIN_DEN: 0.1118712, MRR: 0.4531827, NDCG: 0.2366566, F1: 0.0846248, HIT_RATE: 0.9011223, ARHR_ALL_HITS: 0.7065357, NOVELTY: 0.0056514, AVERAGE_POPULARITY: 0.5108494, DIVERSITY_MEAN_INTER_LIST: 0.9036192, DIVERSITY_HERFINDAHL: 0.9903553, COVERAGE_ITEM: 0.1532200, COVERAGE_ITEM_CORRECT: 0.0992857, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.9000000, DIVERSITY_GINI: 0.0199961, SHANNON_ENTROPY: 8.3035103, RATIO_DIVERSITY_HERFINDAHL: 0.9907263, RATIO_DIVERSITY_GINI: 0.0767854, RATIO_SHANNON_ENTROPY: 0.6669670, RATIO_AVERAGE_POPULARITY: 2.5930082, RATIO_NOVELTY: 0.0332919, 
SearchBayesianSkopt: Config 24 is suboptimal. Config: {'epochs': 58, 'learning_rate': 0.00020354388411968248, 'l2_reg': 0.001262947715375635, 'dropout': 0.691950393908682, 'total_anneal_steps': 483330, 'anneal_cap': 0.49720133391349763, 'batch_size': 512, 'encoding_size': 492, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - results: PRECISION: 0.2193281, PRECISION_RECALL_MIN_DEN: 0.2209559, RECALL: 0.0483358, MAP: 0.1069355, MAP_MIN_DEN: 0.1078265, MRR: 0.4514325, NDCG: 0.2292087, F1: 0.0792142, HIT_RATE: 0.8846916, ARHR_ALL_HITS: 0.6918577, NOVELTY: 0.0054993, AVERAGE_POPULARITY: 0.5668848, DIVERSITY_MEAN_INTER_LIST: 0.8719498, DIVERSITY_HERFINDAHL: 0.9871886, COVERAGE_ITEM: 0.0576998, COVERAGE_ITEM_CORRECT: 0.0410875, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8835897, DIVERSITY_GINI: 0.0084078, SHANNON_ENTROPY: 7.3902111, RATIO_DIVERSITY_HERFINDAHL: 0.9875584, RATIO_DIVERSITY_GINI: 0.0322860, RATIO_SHANNON_ENTROPY: 0.5936076, RATIO_AVERAGE_POPULARITY: 2.8774365, RATIO_NOVELTY: 0.0323956, 
SearchBayesianSkopt: Config 25 is suboptimal. Config: {'epochs': 16, 'learning_rate': 0.0005313159186257336, 'l2_reg': 9.150676597647341e-05, 'dropout': 0.5427329429837288, 'total_anneal_steps': 272493, 'anneal_cap': 0.32044912143015725, 'batch_size': 1024, 'encoding_size': 296, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2149784, PRECISION_RECALL_MIN_DEN: 0.2165467, RECALL: 0.0475874, MAP: 0.1043384, MAP_MIN_DEN: 0.1052026, MRR: 0.4459124, NDCG: 0.2248802, F1: 0.0779253, HIT_RATE: 0.8834446, ARHR_ALL_HITS: 0.6791938, NOVELTY: 0.0055507, AVERAGE_POPULARITY: 0.5515483, DIVERSITY_MEAN_INTER_LIST: 0.8680547, DIVERSITY_HERFINDAHL: 0.9867991, COVERAGE_ITEM: 0.0708234, COVERAGE_ITEM_CORRECT: 0.0482862, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8823443, DIVERSITY_GINI: 0.0093706, SHANNON_ENTROPY: 7.4828075, RATIO_DIVERSITY_HERFINDAHL: 0.9871688, RATIO_DIVERSITY_GINI: 0.0359835, RATIO_SHANNON_ENTROPY: 0.6010453, RATIO_AVERAGE_POPULARITY: 2.7995906, RATIO_NOVELTY: 0.0326988, 
SearchBayesianSkopt: Config 26 is suboptimal. Config: {'epochs': 101, 'learning_rate': 2.8441019573088445e-06, 'l2_reg': 0.0014234555369950516, 'dropout': 0.48400988412111423, 'total_anneal_steps': 460089, 'anneal_cap': 0.5568944992691767, 'batch_size': 128, 'encoding_size': 348, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1861879, PRECISION_RECALL_MIN_DEN: 0.1875394, RECALL: 0.0392006, MAP: 0.0903858, MAP_MIN_DEN: 0.0911488, MRR: 0.4197111, NDCG: 0.1990391, F1: 0.0647653, HIT_RATE: 0.8264505, ARHR_ALL_HITS: 0.6129084, NOVELTY: 0.0051386, AVERAGE_POPULARITY: 0.7602806, DIVERSITY_MEAN_INTER_LIST: 0.5056619, DIVERSITY_HERFINDAHL: 0.9505625, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8254212, DIVERSITY_GINI: 0.0010729, SHANNON_ENTROPY: 4.4673716, RATIO_DIVERSITY_HERFINDAHL: 0.9509186, RATIO_DIVERSITY_GINI: 0.0041201, RATIO_SHANNON_ENTROPY: 0.3588349, RATIO_AVERAGE_POPULARITY: 3.8590899, RATIO_NOVELTY: 0.0302709, 
SearchBayesianSkopt: Config 27 is suboptimal. Config: {'epochs': 8, 'learning_rate': 0.005502241160428777, 'l2_reg': 0.003191044595153814, 'dropout': 0.35721719462789353, 'total_anneal_steps': 207331, 'anneal_cap': 0.023742727046941383, 'batch_size': 512, 'encoding_size': 192, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2168488, PRECISION_RECALL_MIN_DEN: 0.2185165, RECALL: 0.0491138, MAP: 0.1033100, MAP_MIN_DEN: 0.1042135, MRR: 0.4402556, NDCG: 0.2245688, F1: 0.0800884, HIT_RATE: 0.8875523, ARHR_ALL_HITS: 0.6722014, NOVELTY: 0.0057271, AVERAGE_POPULARITY: 0.4859895, DIVERSITY_MEAN_INTER_LIST: 0.9131872, DIVERSITY_HERFINDAHL: 0.9913120, COVERAGE_ITEM: 0.1278587, COVERAGE_ITEM_CORRECT: 0.0799048, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8864469, DIVERSITY_GINI: 0.0178480, SHANNON_ENTROPY: 8.2932751, RATIO_DIVERSITY_HERFINDAHL: 0.9916834, RATIO_DIVERSITY_GINI: 0.0685368, RATIO_SHANNON_ENTROPY: 0.6661449, RATIO_AVERAGE_POPULARITY: 2.4668222, RATIO_NOVELTY: 0.0337375, 
SearchBayesianSkopt: Config 28 is suboptimal. Config: {'epochs': 12, 'learning_rate': 0.00010991360428053014, 'l2_reg': 0.0005683381494059692, 'dropout': 0.685465306109287, 'total_anneal_steps': 205639, 'anneal_cap': 0.4457076924809411, 'batch_size': 512, 'encoding_size': 260, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1856818, PRECISION_RECALL_MIN_DEN: 0.1870077, RECALL: 0.0390716, MAP: 0.0904505, MAP_MIN_DEN: 0.0912145, MRR: 0.4211394, NDCG: 0.1989912, F1: 0.0645587, HIT_RATE: 0.8249101, ARHR_ALL_HITS: 0.6140880, NOVELTY: 0.0051386, AVERAGE_POPULARITY: 0.7602930, DIVERSITY_MEAN_INTER_LIST: 0.5056890, DIVERSITY_HERFINDAHL: 0.9505652, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8238828, DIVERSITY_GINI: 0.0010732, SHANNON_ENTROPY: 4.4676991, RATIO_DIVERSITY_HERFINDAHL: 0.9509213, RATIO_DIVERSITY_GINI: 0.0041211, RATIO_SHANNON_ENTROPY: 0.3588612, RATIO_AVERAGE_POPULARITY: 3.8591528, RATIO_NOVELTY: 0.0302707, 
SearchBayesianSkopt: Config 29 is suboptimal. Config: {'epochs': 36, 'learning_rate': 0.0006042787668338108, 'l2_reg': 1.7638752022754832e-05, 'dropout': 0.7902400137508914, 'total_anneal_steps': 591533, 'anneal_cap': 0.11482002621456876, 'batch_size': 512, 'encoding_size': 65, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2155725, PRECISION_RECALL_MIN_DEN: 0.2171293, RECALL: 0.0474281, MAP: 0.1042708, MAP_MIN_DEN: 0.1049702, MRR: 0.4425075, NDCG: 0.2244597, F1: 0.0777503, HIT_RATE: 0.8777232, ARHR_ALL_HITS: 0.6761650, NOVELTY: 0.0055904, AVERAGE_POPULARITY: 0.5301712, DIVERSITY_MEAN_INTER_LIST: 0.8960610, DIVERSITY_HERFINDAHL: 0.9895995, COVERAGE_ITEM: 0.0714879, COVERAGE_ITEM_CORRECT: 0.0433025, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8766300, DIVERSITY_GINI: 0.0097542, SHANNON_ENTROPY: 7.6682369, RATIO_DIVERSITY_HERFINDAHL: 0.9899702, RATIO_DIVERSITY_GINI: 0.0374563, RATIO_SHANNON_ENTROPY: 0.6159396, RATIO_AVERAGE_POPULARITY: 2.6910830, RATIO_NOVELTY: 0.0329327, 
SearchBayesianSkopt: Config 30 is suboptimal. Config: {'epochs': 46, 'learning_rate': 1.493581078364104e-06, 'l2_reg': 0.01, 'dropout': 0.8, 'total_anneal_steps': 100000, 'anneal_cap': 0.24807605234338193, 'batch_size': 256, 'encoding_size': 512, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1855718, PRECISION_RECALL_MIN_DEN: 0.1869538, RECALL: 0.0391306, MAP: 0.0903529, MAP_MIN_DEN: 0.0911162, MRR: 0.4215421, NDCG: 0.1989608, F1: 0.0646325, HIT_RATE: 0.8268173, ARHR_ALL_HITS: 0.6141184, NOVELTY: 0.0051387, AVERAGE_POPULARITY: 0.7602015, DIVERSITY_MEAN_INTER_LIST: 0.5069926, DIVERSITY_HERFINDAHL: 0.9506955, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0020488, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8257875, DIVERSITY_GINI: 0.0010773, SHANNON_ENTROPY: 4.4742796, RATIO_DIVERSITY_HERFINDAHL: 0.9510517, RATIO_DIVERSITY_GINI: 0.0041367, RATIO_SHANNON_ENTROPY: 0.3593898, RATIO_AVERAGE_POPULARITY: 3.8586884, RATIO_NOVELTY: 0.0302713, 
SearchBayesianSkopt: Config 31 is suboptimal. Config: {'epochs': 10, 'learning_rate': 0.0004661781413593655, 'l2_reg': 0.00021540791604081932, 'dropout': 0.7288222298941278, 'total_anneal_steps': 100000, 'anneal_cap': 0.4448261088666713, 'batch_size': 512, 'encoding_size': 292, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2156092, PRECISION_RECALL_MIN_DEN: 0.2174093, RECALL: 0.0488858, MAP: 0.1029269, MAP_MIN_DEN: 0.1038721, MRR: 0.4416052, NDCG: 0.2239633, F1: 0.0797008, HIT_RATE: 0.8853517, ARHR_ALL_HITS: 0.6717966, NOVELTY: 0.0056735, AVERAGE_POPULARITY: 0.4985617, DIVERSITY_MEAN_INTER_LIST: 0.9111020, DIVERSITY_HERFINDAHL: 0.9911035, COVERAGE_ITEM: 0.1187220, COVERAGE_ITEM_CORRECT: 0.0719863, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8842491, DIVERSITY_GINI: 0.0160363, SHANNON_ENTROPY: 8.1962548, RATIO_DIVERSITY_HERFINDAHL: 0.9914748, RATIO_DIVERSITY_GINI: 0.0615798, RATIO_SHANNON_ENTROPY: 0.6583518, RATIO_AVERAGE_POPULARITY: 2.5306372, RATIO_NOVELTY: 0.0334222, 
SearchBayesianSkopt: Config 32 Exception. Config: {'epochs': 300, 'learning_rate': 0.0002091541148322713, 'l2_reg': 1e-06, 'dropout': 0.0, 'total_anneal_steps': 100000, 'anneal_cap': 0.0, 'batch_size': 128, 'encoding_size': 491, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - Exception: Traceback (most recent call last):
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1380, in _do_call
    return fn(*args)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1363, in _run_fn
    return self._call_tf_sessionrun(options, feed_dict, fetch_list,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1456, in _call_tf_sessionrun
    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) INVALID_ARGUMENT: Nan in summary histogram for: bias_p_1_1
	 [[{{node bias_p_1_1}}]]
	 [[weight_p_0to1_1/ReadVariableOp/_74]]
  (1) INVALID_ARGUMENT: Nan in summary histogram for: bias_p_1_1
	 [[{{node bias_p_1_1}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 341, in fit
    raise e
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 332, in fit
    self._train_with_early_stopping(epochs,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Incremental_Training_Early_Stopping.py", line 177, in _train_with_early_stopping
    self._run_epoch(epochs_current)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 385, in _run_epoch
    summary_train = self.sess.run(self.merged_var, feed_dict=feed_dict)
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 970, in run
    result = self._run(None, fetches, feed_dict, options_ptr,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1193, in _run
    results = self._do_run(handle, final_targets, final_fetches,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1373, in _do_run
    return self._do_call(_run_fn, feeds, fetches, targets, options,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\client\session.py", line 1399, in _do_call
    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) INVALID_ARGUMENT: Nan in summary histogram for: bias_p_1_1
	 [[node bias_p_1_1
 (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:227)
]]
	 [[weight_p_0to1_1/ReadVariableOp/_74]]
  (1) INVALID_ARGUMENT: Nan in summary histogram for: bias_p_1_1
	 [[node bias_p_1_1
 (defined at C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py:227)
]]
0 successful operations.
0 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node bias_p_1_1:
In[0] bias_p_1_1/tag:	
In[1] bias_p_1_1/ReadVariableOp:

Operation defined at: (most recent call last)
>>>   File "C:/Users/Andrea/Documents/GitHub/recsys-challenge-polimi-2021/main.py", line 13, in <module>
>>>     hyperparameter_tuning()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\hyperparameter_tuning.py", line 113, in hyperparameter_tuning
>>>     runHyperparameterSearch_Collaborative(recommender_class,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\run_hyperparameter_search.py", line 968, in runHyperparameterSearch_Collaborative
>>>     hyperparameterSearch.search(recommender_input_args,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 338, in search
>>>     self.result = gp_minimize(self._objective_function_list_input,
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\gp.py", line 259, in gp_minimize
>>>     return base_minimize(
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\base.py", line 299, in base_minimize
>>>     next_y = func(next_x)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 412, in _objective_function_list_input
>>>     result = self._objective_function(current_fit_hyperparameters_dict)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
>>>     result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
>>>     recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
>>>     recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
>>>     super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 302, in fit
>>>     self.saver, self.logits_var, self.loss_var, self.train_op_var, self.merged_var = self.vae.build_graph()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 120, in build_graph
>>>     self._construct_weights()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 227, in _construct_weights
>>>     tf.compat.v1.summary.histogram(bias_key, self.biases_p[-1])
>>> 

Input Source operations connected to node bias_p_1_1:
In[0] bias_p_1_1/tag:	
In[1] bias_p_1_1/ReadVariableOp:

Operation defined at: (most recent call last)
>>>   File "C:/Users/Andrea/Documents/GitHub/recsys-challenge-polimi-2021/main.py", line 13, in <module>
>>>     hyperparameter_tuning()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\hyperparameter_tuning.py", line 113, in hyperparameter_tuning
>>>     runHyperparameterSearch_Collaborative(recommender_class,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\run_hyperparameter_search.py", line 968, in runHyperparameterSearch_Collaborative
>>>     hyperparameterSearch.search(recommender_input_args,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 338, in search
>>>     self.result = gp_minimize(self._objective_function_list_input,
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\gp.py", line 259, in gp_minimize
>>>     return base_minimize(
>>> 
>>>   File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\base.py", line 299, in base_minimize
>>>     next_y = func(next_x)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 412, in _objective_function_list_input
>>>     result = self._objective_function(current_fit_hyperparameters_dict)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
>>>     result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
>>>     recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
>>>     recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
>>>     super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 302, in fit
>>>     self.saver, self.logits_var, self.loss_var, self.train_op_var, self.merged_var = self.vae.build_graph()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 120, in build_graph
>>>     self._construct_weights()
>>> 
>>>   File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 227, in _construct_weights
>>>     tf.compat.v1.summary.histogram(bias_key, self.biases_p[-1])
>>> 

Original stack trace for 'bias_p_1_1':
  File "C:/Users/Andrea/Documents/GitHub/recsys-challenge-polimi-2021/main.py", line 13, in <module>
    hyperparameter_tuning()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\hyperparameter_tuning.py", line 113, in hyperparameter_tuning
    runHyperparameterSearch_Collaborative(recommender_class,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\run_hyperparameter_search.py", line 968, in runHyperparameterSearch_Collaborative
    hyperparameterSearch.search(recommender_input_args,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 338, in search
    self.result = gp_minimize(self._objective_function_list_input,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\gp.py", line 259, in gp_minimize
    return base_minimize(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\skopt\optimizer\base.py", line 299, in base_minimize
    next_y = func(next_x)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchBayesianSkopt.py", line 412, in _objective_function_list_input
    result = self._objective_function(current_fit_hyperparameters_dict)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 464, in _objective_function
    result_df, recommender_instance = self._evaluate_on_validation(current_fit_hyperparameters_dict, was_already_evaluated_flag, was_already_evaluated_index)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 332, in _evaluate_on_validation
    recommender_instance, train_time = self._fit_model(current_fit_hyperparameters)
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\HyperparameterTuning\SearchAbstractClass.py", line 304, in _fit_model
    recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 504, in fit
    super(MultVAERecommender_OptimizerMask, self).fit(epochs=epochs, batch_size=batch_size, dropout=dropout, learning_rate=learning_rate,
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 302, in fit
    self.saver, self.logits_var, self.loss_var, self.train_op_var, self.merged_var = self.vae.build_graph()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 120, in build_graph
    self._construct_weights()
  File "C:\Users\Andrea\Documents\GitHub\recsys-challenge-polimi-2021\src\exercise-sessions-code\Recommenders\Neural\MultVAERecommender.py", line 227, in _construct_weights
    tf.compat.v1.summary.histogram(bias_key, self.biases_p[-1])
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\summary\summary.py", line 258, in histogram
    val = _gen_logging_ops.histogram_summary(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\ops\gen_logging_ops.py", line 284, in histogram_summary
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 744, in _apply_op_helper
    op = g._create_op_internal(op_type_name, inputs, dtypes=None,
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\framework\ops.py", line 3697, in _create_op_internal
    ret = Operation(
  File "D:\Developer\anaconda3\envs\recsys\lib\site-packages\tensorflow\python\framework\ops.py", line 2101, in __init__
    self._traceback = tf_stack.extract_stack_for_node(self._c_op)


SearchBayesianSkopt: Config 33 is suboptimal. Config: {'epochs': 20, 'learning_rate': 0.0002696476829469832, 'l2_reg': 0.0012739914716930277, 'dropout': 0.2702187785247861, 'total_anneal_steps': 258180, 'anneal_cap': 0.5252675508634752, 'batch_size': 256, 'encoding_size': 112, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2169222, PRECISION_RECALL_MIN_DEN: 0.2185414, RECALL: 0.0481548, MAP: 0.1047469, MAP_MIN_DEN: 0.1056222, MRR: 0.4442781, NDCG: 0.2259606, F1: 0.0788136, HIT_RATE: 0.8842514, ARHR_ALL_HITS: 0.6798771, NOVELTY: 0.0055037, AVERAGE_POPULARITY: 0.5653332, DIVERSITY_MEAN_INTER_LIST: 0.8630522, DIVERSITY_HERFINDAHL: 0.9862989, COVERAGE_ITEM: 0.0512210, COVERAGE_ITEM_CORRECT: 0.0380420, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8831502, DIVERSITY_GINI: 0.0075220, SHANNON_ENTROPY: 7.2721538, RATIO_DIVERSITY_HERFINDAHL: 0.9866683, RATIO_DIVERSITY_GINI: 0.0288848, RATIO_SHANNON_ENTROPY: 0.5841248, RATIO_AVERAGE_POPULARITY: 2.8695611, RATIO_NOVELTY: 0.0324217, 
SearchBayesianSkopt: Config 34 is suboptimal. Config: {'epochs': 12, 'learning_rate': 0.0003260479901774014, 'l2_reg': 0.0012686901691668822, 'dropout': 0.2697347268418434, 'total_anneal_steps': 249968, 'anneal_cap': 0.3337366548138662, 'batch_size': 512, 'encoding_size': 59, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1882931, PRECISION_RECALL_MIN_DEN: 0.1895971, RECALL: 0.0394915, MAP: 0.0918422, MAP_MIN_DEN: 0.0926087, MRR: 0.4248992, NDCG: 0.2016223, F1: 0.0652895, HIT_RATE: 0.8330522, ARHR_ALL_HITS: 0.6217367, NOVELTY: 0.0051934, AVERAGE_POPULARITY: 0.7348679, DIVERSITY_MEAN_INTER_LIST: 0.5693989, DIVERSITY_HERFINDAHL: 0.9569357, COVERAGE_ITEM: 0.0042638, COVERAGE_ITEM_CORRECT: 0.0037654, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8320147, DIVERSITY_GINI: 0.0012382, SHANNON_ENTROPY: 4.7834673, RATIO_DIVERSITY_HERFINDAHL: 0.9572942, RATIO_DIVERSITY_GINI: 0.0047549, RATIO_SHANNON_ENTROPY: 0.3842248, RATIO_AVERAGE_POPULARITY: 3.7300980, RATIO_NOVELTY: 0.0305939, 
SearchBayesianSkopt: Config 35 is suboptimal. Config: {'epochs': 127, 'learning_rate': 0.0001156064933506552, 'l2_reg': 5.39121864111235e-05, 'dropout': 0.5770799991359664, 'total_anneal_steps': 314507, 'anneal_cap': 0.5242715440497667, 'batch_size': 512, 'encoding_size': 366, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2223428, PRECISION_RECALL_MIN_DEN: 0.2241105, RECALL: 0.0495497, MAP: 0.1080649, MAP_MIN_DEN: 0.1089972, MRR: 0.4525011, NDCG: 0.2313951, F1: 0.0810396, HIT_RATE: 0.8902663, ARHR_ALL_HITS: 0.6957453, NOVELTY: 0.0055650, AVERAGE_POPULARITY: 0.5400655, DIVERSITY_MEAN_INTER_LIST: 0.8895863, DIVERSITY_HERFINDAHL: 0.9889521, COVERAGE_ITEM: 0.0901490, COVERAGE_ITEM_CORRECT: 0.0607453, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8891575, DIVERSITY_GINI: 0.0120577, SHANNON_ENTROPY: 7.7979730, RATIO_DIVERSITY_HERFINDAHL: 0.9893226, RATIO_DIVERSITY_GINI: 0.0463017, RATIO_SHANNON_ENTROPY: 0.6263605, RATIO_AVERAGE_POPULARITY: 2.7413055, RATIO_NOVELTY: 0.0327827, 
SearchBayesianSkopt: Config 36 is suboptimal. Config: {'epochs': 37, 'learning_rate': 0.00011156685343788045, 'l2_reg': 1.3827981276428942e-05, 'dropout': 0.5767675638519296, 'total_anneal_steps': 295986, 'anneal_cap': 0.40573533557865105, 'batch_size': 512, 'encoding_size': 182, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2174943, PRECISION_RECALL_MIN_DEN: 0.2191468, RECALL: 0.0478671, MAP: 0.1052906, MAP_MIN_DEN: 0.1061688, MRR: 0.4475285, NDCG: 0.2267848, F1: 0.0784653, HIT_RATE: 0.8857185, ARHR_ALL_HITS: 0.6832602, NOVELTY: 0.0054989, AVERAGE_POPULARITY: 0.5733033, DIVERSITY_MEAN_INTER_LIST: 0.8562011, DIVERSITY_HERFINDAHL: 0.9856138, COVERAGE_ITEM: 0.0593610, COVERAGE_ITEM_CORRECT: 0.0410322, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8846154, DIVERSITY_GINI: 0.0078648, SHANNON_ENTROPY: 7.2633913, RATIO_DIVERSITY_HERFINDAHL: 0.9859830, RATIO_DIVERSITY_GINI: 0.0302009, RATIO_SHANNON_ENTROPY: 0.5834210, RATIO_AVERAGE_POPULARITY: 2.9100163, RATIO_NOVELTY: 0.0323937, 
SearchBayesianSkopt: Config 37 is suboptimal. Config: {'epochs': 101, 'learning_rate': 2.871589867781626e-06, 'l2_reg': 0.001099537655864506, 'dropout': 0.4831191204032417, 'total_anneal_steps': 447176, 'anneal_cap': 0.5634552621954192, 'batch_size': 128, 'encoding_size': 340, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1860632, PRECISION_RECALL_MIN_DEN: 0.1873981, RECALL: 0.0391459, MAP: 0.0902861, MAP_MIN_DEN: 0.0910528, MRR: 0.4194580, NDCG: 0.1988933, F1: 0.0646832, HIT_RATE: 0.8260838, ARHR_ALL_HITS: 0.6124276, NOVELTY: 0.0051385, AVERAGE_POPULARITY: 0.7603675, DIVERSITY_MEAN_INTER_LIST: 0.5052973, DIVERSITY_HERFINDAHL: 0.9505260, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8250549, DIVERSITY_GINI: 0.0010720, SHANNON_ENTROPY: 4.4664187, RATIO_DIVERSITY_HERFINDAHL: 0.9508821, RATIO_DIVERSITY_GINI: 0.0041167, RATIO_SHANNON_ENTROPY: 0.3587584, RATIO_AVERAGE_POPULARITY: 3.8595307, RATIO_NOVELTY: 0.0302702, 
SearchBayesianSkopt: Config 38 is suboptimal. Config: {'epochs': 76, 'learning_rate': 1.2648608406810024e-06, 'l2_reg': 0.000511832536799186, 'dropout': 0.7521395056181546, 'total_anneal_steps': 197349, 'anneal_cap': 0.26395182921306276, 'batch_size': 512, 'encoding_size': 472, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1859459, PRECISION_RECALL_MIN_DEN: 0.1872849, RECALL: 0.0391685, MAP: 0.0902957, MAP_MIN_DEN: 0.0909443, MRR: 0.4195038, NDCG: 0.1988000, F1: 0.0647069, HIT_RATE: 0.8267439, ARHR_ALL_HITS: 0.6126072, NOVELTY: 0.0051388, AVERAGE_POPULARITY: 0.7601157, DIVERSITY_MEAN_INTER_LIST: 0.5071084, DIVERSITY_HERFINDAHL: 0.9507071, COVERAGE_ITEM: 0.0022703, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8257143, DIVERSITY_GINI: 0.0010758, SHANNON_ENTROPY: 4.4736004, RATIO_DIVERSITY_HERFINDAHL: 0.9510633, RATIO_DIVERSITY_GINI: 0.0041310, RATIO_SHANNON_ENTROPY: 0.3593352, RATIO_AVERAGE_POPULARITY: 3.8582529, RATIO_NOVELTY: 0.0302718, 
SearchBayesianSkopt: Config 39 is suboptimal. Config: {'epochs': 20, 'learning_rate': 0.003747550598923109, 'l2_reg': 0.0016139804671454626, 'dropout': 0.038786777001798514, 'total_anneal_steps': 378160, 'anneal_cap': 0.37156036514111945, 'batch_size': 512, 'encoding_size': 78, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2108780, PRECISION_RECALL_MIN_DEN: 0.2123196, RECALL: 0.0447732, MAP: 0.1029629, MAP_MIN_DEN: 0.1037750, MRR: 0.4434321, NDCG: 0.2217592, F1: 0.0738637, HIT_RATE: 0.8667205, ARHR_ALL_HITS: 0.6732140, NOVELTY: 0.0052564, AVERAGE_POPULARITY: 0.6936481, DIVERSITY_MEAN_INTER_LIST: 0.6966749, DIVERSITY_HERFINDAHL: 0.9696624, COVERAGE_ITEM: 0.0295144, COVERAGE_ITEM_CORRECT: 0.0218174, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8656410, DIVERSITY_GINI: 0.0025861, SHANNON_ENTROPY: 5.7484451, RATIO_DIVERSITY_HERFINDAHL: 0.9700256, RATIO_DIVERSITY_GINI: 0.0099306, RATIO_SHANNON_ENTROPY: 0.4617352, RATIO_AVERAGE_POPULARITY: 3.5208715, RATIO_NOVELTY: 0.0309648, 
SearchBayesianSkopt: Config 40 is suboptimal. Config: {'epochs': 15, 'learning_rate': 0.0007666924626117576, 'l2_reg': 0.0032646551028726084, 'dropout': 0.063988045107302, 'total_anneal_steps': 537620, 'anneal_cap': 0.2537956498097951, 'batch_size': 512, 'encoding_size': 4, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1868921, PRECISION_RECALL_MIN_DEN: 0.1882456, RECALL: 0.0393007, MAP: 0.0912297, MAP_MIN_DEN: 0.0920027, MRR: 0.4242544, NDCG: 0.2005564, F1: 0.0649445, HIT_RATE: 0.8295313, ARHR_ALL_HITS: 0.6194479, NOVELTY: 0.0051775, AVERAGE_POPULARITY: 0.7426310, DIVERSITY_MEAN_INTER_LIST: 0.5417682, DIVERSITY_HERFINDAHL: 0.9541728, COVERAGE_ITEM: 0.0039316, COVERAGE_ITEM_CORRECT: 0.0032671, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8284982, DIVERSITY_GINI: 0.0011716, SHANNON_ENTROPY: 4.6724058, RATIO_DIVERSITY_HERFINDAHL: 0.9545303, RATIO_DIVERSITY_GINI: 0.0044990, RATIO_SHANNON_ENTROPY: 0.3753040, RATIO_AVERAGE_POPULARITY: 3.7695024, RATIO_NOVELTY: 0.0305000, 
SearchBayesianSkopt: Config 41 is suboptimal. Config: {'epochs': 3, 'learning_rate': 0.0009465149995937549, 'l2_reg': 4.046827908105667e-05, 'dropout': 0.3965490280190369, 'total_anneal_steps': 414489, 'anneal_cap': 0.022344888878130284, 'batch_size': 128, 'encoding_size': 437, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2157706, PRECISION_RECALL_MIN_DEN: 0.2174005, RECALL: 0.0485932, MAP: 0.1030186, MAP_MIN_DEN: 0.1038987, MRR: 0.4370670, NDCG: 0.2234748, F1: 0.0793224, HIT_RATE: 0.8863053, ARHR_ALL_HITS: 0.6688160, NOVELTY: 0.0056250, AVERAGE_POPULARITY: 0.5335662, DIVERSITY_MEAN_INTER_LIST: 0.8744456, DIVERSITY_HERFINDAHL: 0.9874381, COVERAGE_ITEM: 0.1241486, COVERAGE_ITEM_CORRECT: 0.0737029, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8852015, DIVERSITY_GINI: 0.0143080, SHANNON_ENTROPY: 7.8110287, RATIO_DIVERSITY_HERFINDAHL: 0.9878080, RATIO_DIVERSITY_GINI: 0.0549433, RATIO_SHANNON_ENTROPY: 0.6274091, RATIO_AVERAGE_POPULARITY: 2.7083157, RATIO_NOVELTY: 0.0331361, 
SearchBayesianSkopt: Config 42 is suboptimal. Config: {'epochs': 300, 'learning_rate': 1.1037948960936313e-06, 'l2_reg': 6.2847109378929255e-06, 'dropout': 0.19790989009679139, 'total_anneal_steps': 491453, 'anneal_cap': 0.36581978031759815, 'batch_size': 256, 'encoding_size': 422, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1727499, PRECISION_RECALL_MIN_DEN: 0.1739469, RECALL: 0.0356588, MAP: 0.0793065, MAP_MIN_DEN: 0.0797124, MRR: 0.3720875, NDCG: 0.1799429, F1: 0.0591152, HIT_RATE: 0.8027580, ARHR_ALL_HITS: 0.5418043, NOVELTY: 0.0051794, AVERAGE_POPULARITY: 0.7268189, DIVERSITY_MEAN_INTER_LIST: 0.4874709, DIVERSITY_HERFINDAHL: 0.9487435, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8017582, DIVERSITY_GINI: 0.0010292, SHANNON_ENTROPY: 4.4205611, RATIO_DIVERSITY_HERFINDAHL: 0.9490989, RATIO_DIVERSITY_GINI: 0.0039522, RATIO_SHANNON_ENTROPY: 0.3550749, RATIO_AVERAGE_POPULARITY: 3.6892425, RATIO_NOVELTY: 0.0305116, 
SearchBayesianSkopt: Config 43 is suboptimal. Config: {'epochs': 40, 'learning_rate': 4.9164339832025034e-05, 'l2_reg': 0.0010804482790832024, 'dropout': 0.10332127891303398, 'total_anneal_steps': 445094, 'anneal_cap': 0.4337984137250088, 'batch_size': 512, 'encoding_size': 86, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1858505, PRECISION_RECALL_MIN_DEN: 0.1871995, RECALL: 0.0391332, MAP: 0.0903799, MAP_MIN_DEN: 0.0911467, MRR: 0.4209215, NDCG: 0.1990100, F1: 0.0646528, HIT_RATE: 0.8260104, ARHR_ALL_HITS: 0.6137298, NOVELTY: 0.0051384, AVERAGE_POPULARITY: 0.7604538, DIVERSITY_MEAN_INTER_LIST: 0.5054607, DIVERSITY_HERFINDAHL: 0.9505424, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8249817, DIVERSITY_GINI: 0.0010730, SHANNON_ENTROPY: 4.4655509, RATIO_DIVERSITY_HERFINDAHL: 0.9508984, RATIO_DIVERSITY_GINI: 0.0041204, RATIO_SHANNON_ENTROPY: 0.3586887, RATIO_AVERAGE_POPULARITY: 3.8599687, RATIO_NOVELTY: 0.0302696, 
SearchBayesianSkopt: Config 44 is suboptimal. Config: {'epochs': 300, 'learning_rate': 3.417370785948676e-06, 'l2_reg': 2.3018342937461742e-05, 'dropout': 0.6716394766032099, 'total_anneal_steps': 332925, 'anneal_cap': 0.5956645685356721, 'batch_size': 512, 'encoding_size': 137, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1783320, PRECISION_RECALL_MIN_DEN: 0.1796149, RECALL: 0.0371051, MAP: 0.0832142, MAP_MIN_DEN: 0.0836877, MRR: 0.3852944, NDCG: 0.1865211, F1: 0.0614289, HIT_RATE: 0.8117069, ARHR_ALL_HITS: 0.5638774, NOVELTY: 0.0051629, AVERAGE_POPULARITY: 0.7399703, DIVERSITY_MEAN_INTER_LIST: 0.4958959, DIVERSITY_HERFINDAHL: 0.9495860, COVERAGE_ITEM: 0.0023257, COVERAGE_ITEM_CORRECT: 0.0021596, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8106960, DIVERSITY_GINI: 0.0010541, SHANNON_ENTROPY: 4.4412368, RATIO_DIVERSITY_HERFINDAHL: 0.9499417, RATIO_DIVERSITY_GINI: 0.0040477, RATIO_SHANNON_ENTROPY: 0.3567357, RATIO_AVERAGE_POPULARITY: 3.7559974, RATIO_NOVELTY: 0.0304143, 
SearchBayesianSkopt: Config 45 is suboptimal. Config: {'epochs': 47, 'learning_rate': 0.00029378304563348483, 'l2_reg': 0.01, 'dropout': 0.27157471019454715, 'total_anneal_steps': 230575, 'anneal_cap': 2.2488748484228653e-05, 'batch_size': 1024, 'encoding_size': 11, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1859752, PRECISION_RECALL_MIN_DEN: 0.1873088, RECALL: 0.0391260, MAP: 0.0902362, MAP_MIN_DEN: 0.0910061, MRR: 0.4192377, NDCG: 0.1988134, F1: 0.0646507, HIT_RATE: 0.8263772, ARHR_ALL_HITS: 0.6121641, NOVELTY: 0.0051407, AVERAGE_POPULARITY: 0.7601663, DIVERSITY_MEAN_INTER_LIST: 0.5054203, DIVERSITY_HERFINDAHL: 0.9505383, COVERAGE_ITEM: 0.0038762, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8253480, DIVERSITY_GINI: 0.0010726, SHANNON_ENTROPY: 4.4705271, RATIO_DIVERSITY_HERFINDAHL: 0.9508944, RATIO_DIVERSITY_GINI: 0.0041187, RATIO_SHANNON_ENTROPY: 0.3590884, RATIO_AVERAGE_POPULARITY: 3.8585095, RATIO_NOVELTY: 0.0302836, 
SearchBayesianSkopt: Config 46 is suboptimal. Config: {'epochs': 4, 'learning_rate': 0.00011010977143932868, 'l2_reg': 7.670939029862953e-06, 'dropout': 0.5762364391907667, 'total_anneal_steps': 253113, 'anneal_cap': 0.3376384667234934, 'batch_size': 512, 'encoding_size': 99, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1858872, PRECISION_RECALL_MIN_DEN: 0.1871701, RECALL: 0.0390366, MAP: 0.0902747, MAP_MIN_DEN: 0.0910405, MRR: 0.4187043, NDCG: 0.1986773, F1: 0.0645232, HIT_RATE: 0.8260104, ARHR_ALL_HITS: 0.6117486, NOVELTY: 0.0051398, AVERAGE_POPULARITY: 0.7592466, DIVERSITY_MEAN_INTER_LIST: 0.5077046, DIVERSITY_HERFINDAHL: 0.9507667, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8249817, DIVERSITY_GINI: 0.0010749, SHANNON_ENTROPY: 4.4794882, RATIO_DIVERSITY_HERFINDAHL: 0.9511229, RATIO_DIVERSITY_GINI: 0.0041278, RATIO_SHANNON_ENTROPY: 0.3598082, RATIO_AVERAGE_POPULARITY: 3.8538411, RATIO_NOVELTY: 0.0302780, 
SearchBayesianSkopt: Config 47 is suboptimal. Config: {'epochs': 12, 'learning_rate': 0.0005198624044633187, 'l2_reg': 0.00012121826993923643, 'dropout': 0.5415925432781639, 'total_anneal_steps': 373028, 'anneal_cap': 0.41768566649889965, 'batch_size': 1024, 'encoding_size': 312, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2148170, PRECISION_RECALL_MIN_DEN: 0.2164592, RECALL: 0.0476621, MAP: 0.1036055, MAP_MIN_DEN: 0.1045003, MRR: 0.4420227, NDCG: 0.2238686, F1: 0.0780148, HIT_RATE: 0.8815374, ARHR_ALL_HITS: 0.6738233, NOVELTY: 0.0055539, AVERAGE_POPULARITY: 0.5470600, DIVERSITY_MEAN_INTER_LIST: 0.8810489, DIVERSITY_HERFINDAHL: 0.9880984, COVERAGE_ITEM: 0.0732045, COVERAGE_ITEM_CORRECT: 0.0502243, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8804396, DIVERSITY_GINI: 0.0102575, SHANNON_ENTROPY: 7.6147924, RATIO_DIVERSITY_HERFINDAHL: 0.9884686, RATIO_DIVERSITY_GINI: 0.0393892, RATIO_SHANNON_ENTROPY: 0.6116467, RATIO_AVERAGE_POPULARITY: 2.7768088, RATIO_NOVELTY: 0.0327172, 
SearchBayesianSkopt: Config 48 is suboptimal. Config: {'epochs': 15, 'learning_rate': 0.0001996517667920499, 'l2_reg': 8.346441084571327e-05, 'dropout': 0.09215884877895493, 'total_anneal_steps': 148173, 'anneal_cap': 0.4314469993029871, 'batch_size': 1024, 'encoding_size': 340, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - results: PRECISION: 0.1864520, PRECISION_RECALL_MIN_DEN: 0.1877918, RECALL: 0.0392937, MAP: 0.0906469, MAP_MIN_DEN: 0.0914105, MRR: 0.4201962, NDCG: 0.1994098, F1: 0.0649084, HIT_RATE: 0.8258637, ARHR_ALL_HITS: 0.6142597, NOVELTY: 0.0051389, AVERAGE_POPULARITY: 0.7600428, DIVERSITY_MEAN_INTER_LIST: 0.5070166, DIVERSITY_HERFINDAHL: 0.9506979, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8248352, DIVERSITY_GINI: 0.0010778, SHANNON_ENTROPY: 4.4713428, RATIO_DIVERSITY_HERFINDAHL: 0.9510541, RATIO_DIVERSITY_GINI: 0.0041387, RATIO_SHANNON_ENTROPY: 0.3591539, RATIO_AVERAGE_POPULARITY: 3.8578829, RATIO_NOVELTY: 0.0302725, 
SearchBayesianSkopt: New best config found. Config 49: {'epochs': 26, 'learning_rate': 0.0008692067143251014, 'l2_reg': 0.001528399179340595, 'dropout': 0.6305206323644355, 'total_anneal_steps': 554864, 'anneal_cap': 0.3659360905307019, 'batch_size': 128, 'encoding_size': 442, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2301694, PRECISION_RECALL_MIN_DEN: 0.2320309, RECALL: 0.0525012, MAP: 0.1116772, MAP_MIN_DEN: 0.1126443, MRR: 0.4549591, NDCG: 0.2378416, F1: 0.0855000, HIT_RATE: 0.9017824, ARHR_ALL_HITS: 0.7103237, NOVELTY: 0.0056846, AVERAGE_POPULARITY: 0.4812977, DIVERSITY_MEAN_INTER_LIST: 0.9281672, DIVERSITY_HERFINDAHL: 0.9928099, COVERAGE_ITEM: 0.1202171, COVERAGE_ITEM_CORRECT: 0.0833933, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.9006593, DIVERSITY_GINI: 0.0196365, SHANNON_ENTROPY: 8.5334731, RATIO_DIVERSITY_HERFINDAHL: 0.9931818, RATIO_DIVERSITY_GINI: 0.0754048, RATIO_SHANNON_ENTROPY: 0.6854384, RATIO_AVERAGE_POPULARITY: 2.4430071, RATIO_NOVELTY: 0.0334871, 
SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 26, 'learning_rate': 0.0008692067143251014, 'l2_reg': 0.001528399179340595, 'dropout': 0.6305206323644355, 'total_anneal_steps': 554864, 'anneal_cap': 0.3659360905307019, 'batch_size': 128, 'encoding_size': 442, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.2885346, PRECISION_RECALL_MIN_DEN: 0.2900424, RECALL: 0.0531391, MAP: 0.1526137, MAP_MIN_DEN: 0.1533331, MRR: 0.5278093, NDCG: 0.2975856, F1: 0.0897491, HIT_RATE: 0.9426728, ARHR_ALL_HITS: 0.8909613, NOVELTY: 0.0056842, AVERAGE_POPULARITY: 0.4814879, DIVERSITY_MEAN_INTER_LIST: 0.9280155, DIVERSITY_HERFINDAHL: 0.9927947, COVERAGE_ITEM: 0.1202171, COVERAGE_ITEM_CORRECT: 0.0879340, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.9420513, DIVERSITY_GINI: 0.0196246, SHANNON_ENTROPY: 8.5317328, RATIO_DIVERSITY_HERFINDAHL: 0.9931666, RATIO_DIVERSITY_GINI: 0.0753589, RATIO_SHANNON_ENTROPY: 0.6852986, RATIO_AVERAGE_POPULARITY: 2.4439725, RATIO_NOVELTY: 0.0334850, 

SearchBayesianSkopt: Config 50 is suboptimal. Config: {'epochs': 9, 'learning_rate': 0.005183902168794778, 'l2_reg': 0.01, 'dropout': 0.35583104820351474, 'total_anneal_steps': 224855, 'anneal_cap': 0.3424467893955816, 'batch_size': 512, 'encoding_size': 230, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2107166, PRECISION_RECALL_MIN_DEN: 0.2124461, RECALL: 0.0478157, MAP: 0.0997738, MAP_MIN_DEN: 0.1006967, MRR: 0.4309883, NDCG: 0.2182754, F1: 0.0779444, HIT_RATE: 0.8780899, ARHR_ALL_HITS: 0.6530461, NOVELTY: 0.0056225, AVERAGE_POPULARITY: 0.5255067, DIVERSITY_MEAN_INTER_LIST: 0.8818221, DIVERSITY_HERFINDAHL: 0.9881757, COVERAGE_ITEM: 0.0837809, COVERAGE_ITEM_CORRECT: 0.0561493, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8769963, DIVERSITY_GINI: 0.0112709, SHANNON_ENTROPY: 7.7095756, RATIO_DIVERSITY_HERFINDAHL: 0.9885459, RATIO_DIVERSITY_GINI: 0.0432807, RATIO_SHANNON_ENTROPY: 0.6192601, RATIO_AVERAGE_POPULARITY: 2.6674066, RATIO_NOVELTY: 0.0331216, 
SearchBayesianSkopt: Config 51 is suboptimal. Config: {'epochs': 13, 'learning_rate': 0.00017869252080490692, 'l2_reg': 0.01, 'dropout': 0.17286009840287722, 'total_anneal_steps': 212250, 'anneal_cap': 0.08034197463314885, 'batch_size': 1024, 'encoding_size': 210, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1857258, PRECISION_RECALL_MIN_DEN: 0.1870768, RECALL: 0.0390885, MAP: 0.0904381, MAP_MIN_DEN: 0.0911996, MRR: 0.4209550, NDCG: 0.1989986, F1: 0.0645843, HIT_RATE: 0.8261571, ARHR_ALL_HITS: 0.6139784, NOVELTY: 0.0051385, AVERAGE_POPULARITY: 0.7603013, DIVERSITY_MEAN_INTER_LIST: 0.5047329, DIVERSITY_HERFINDAHL: 0.9504696, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8251282, DIVERSITY_GINI: 0.0010696, SHANNON_ENTROPY: 4.4645821, RATIO_DIVERSITY_HERFINDAHL: 0.9508256, RATIO_DIVERSITY_GINI: 0.0041073, RATIO_SHANNON_ENTROPY: 0.3586108, RATIO_AVERAGE_POPULARITY: 3.8591946, RATIO_NOVELTY: 0.0302706, 
SearchBayesianSkopt: Config 52 is suboptimal. Config: {'epochs': 6, 'learning_rate': 0.0038045034324039853, 'l2_reg': 0.00020098765521254296, 'dropout': 0.0396374365896023, 'total_anneal_steps': 241840, 'anneal_cap': 0.4051344396868505, 'batch_size': 256, 'encoding_size': 15, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2048339, PRECISION_RECALL_MIN_DEN: 0.2063513, RECALL: 0.0441020, MAP: 0.0984620, MAP_MIN_DEN: 0.0993081, MRR: 0.4287404, NDCG: 0.2142848, F1: 0.0725776, HIT_RATE: 0.8593853, ARHR_ALL_HITS: 0.6471524, NOVELTY: 0.0053009, AVERAGE_POPULARITY: 0.6702463, DIVERSITY_MEAN_INTER_LIST: 0.7405471, DIVERSITY_HERFINDAHL: 0.9740493, COVERAGE_ITEM: 0.0189379, COVERAGE_ITEM_CORRECT: 0.0145080, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8583150, DIVERSITY_GINI: 0.0025992, SHANNON_ENTROPY: 5.9031704, RATIO_DIVERSITY_HERFINDAHL: 0.9744142, RATIO_DIVERSITY_GINI: 0.0099810, RATIO_SHANNON_ENTROPY: 0.4741633, RATIO_AVERAGE_POPULARITY: 3.4020867, RATIO_NOVELTY: 0.0312270, 
SearchBayesianSkopt: Config 53 is suboptimal. Config: {'epochs': 9, 'learning_rate': 8.459019385995698e-05, 'l2_reg': 5.357607015104027e-06, 'dropout': 0.6615774663669356, 'total_anneal_steps': 549314, 'anneal_cap': 0.0, 'batch_size': 512, 'encoding_size': 512, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1860339, PRECISION_RECALL_MIN_DEN: 0.1873620, RECALL: 0.0391352, MAP: 0.0905154, MAP_MIN_DEN: 0.0912843, MRR: 0.4213112, NDCG: 0.1992325, F1: 0.0646667, HIT_RATE: 0.8261571, ARHR_ALL_HITS: 0.6144496, NOVELTY: 0.0051386, AVERAGE_POPULARITY: 0.7602726, DIVERSITY_MEAN_INTER_LIST: 0.5057334, DIVERSITY_HERFINDAHL: 0.9505696, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0020488, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8251282, DIVERSITY_GINI: 0.0010732, SHANNON_ENTROPY: 4.4674257, RATIO_DIVERSITY_HERFINDAHL: 0.9509257, RATIO_DIVERSITY_GINI: 0.0041213, RATIO_SHANNON_ENTROPY: 0.3588393, RATIO_AVERAGE_POPULARITY: 3.8590494, RATIO_NOVELTY: 0.0302708, 
SearchBayesianSkopt: Config 54 is suboptimal. Config: {'epochs': 77, 'learning_rate': 4.819950884793933e-05, 'l2_reg': 0.004046590533450556, 'dropout': 0.1042307296671024, 'total_anneal_steps': 450038, 'anneal_cap': 0.10770023775694479, 'batch_size': 1024, 'encoding_size': 94, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1856818, PRECISION_RECALL_MIN_DEN: 0.1870143, RECALL: 0.0390903, MAP: 0.0903271, MAP_MIN_DEN: 0.0910916, MRR: 0.4208438, NDCG: 0.1989057, F1: 0.0645841, HIT_RATE: 0.8260838, ARHR_ALL_HITS: 0.6135887, NOVELTY: 0.0051384, AVERAGE_POPULARITY: 0.7604599, DIVERSITY_MEAN_INTER_LIST: 0.5053424, DIVERSITY_HERFINDAHL: 0.9505305, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8250549, DIVERSITY_GINI: 0.0010724, SHANNON_ENTROPY: 4.4653274, RATIO_DIVERSITY_HERFINDAHL: 0.9508866, RATIO_DIVERSITY_GINI: 0.0041180, RATIO_SHANNON_ENTROPY: 0.3586707, RATIO_AVERAGE_POPULARITY: 3.8600000, RATIO_NOVELTY: 0.0302695, 
SearchBayesianSkopt: Config 55 is suboptimal. Config: {'epochs': 43, 'learning_rate': 0.0007503332412835185, 'l2_reg': 0.01, 'dropout': 0.06454245692893816, 'total_anneal_steps': 516634, 'anneal_cap': 0.6, 'batch_size': 512, 'encoding_size': 162, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2076212, PRECISION_RECALL_MIN_DEN: 0.2090928, RECALL: 0.0442853, MAP: 0.1013364, MAP_MIN_DEN: 0.1021544, MRR: 0.4393332, NDCG: 0.2186439, F1: 0.0729999, HIT_RATE: 0.8624661, ARHR_ALL_HITS: 0.6644622, NOVELTY: 0.0052044, AVERAGE_POPULARITY: 0.7185126, DIVERSITY_MEAN_INTER_LIST: 0.6688210, DIVERSITY_HERFINDAHL: 0.9668772, COVERAGE_ITEM: 0.0120715, COVERAGE_ITEM_CORRECT: 0.0101888, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8613919, DIVERSITY_GINI: 0.0017882, SHANNON_ENTROPY: 5.3758666, RATIO_DIVERSITY_HERFINDAHL: 0.9672394, RATIO_DIVERSITY_GINI: 0.0068669, RATIO_SHANNON_ENTROPY: 0.4318084, RATIO_AVERAGE_POPULARITY: 3.6470806, RATIO_NOVELTY: 0.0306585, 
SearchBayesianSkopt: Config 56 is suboptimal. Config: {'epochs': 2, 'learning_rate': 0.0038568065766685002, 'l2_reg': 0.003576782512952602, 'dropout': 0.049077397836083676, 'total_anneal_steps': 600000, 'anneal_cap': 0.0, 'batch_size': 128, 'encoding_size': 182, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1607717, PRECISION_RECALL_MIN_DEN: 0.1620115, RECALL: 0.0339537, MAP: 0.0739771, MAP_MIN_DEN: 0.0746359, MRR: 0.3716397, NDCG: 0.1706065, F1: 0.0560666, HIT_RATE: 0.7836133, ARHR_ALL_HITS: 0.5217758, NOVELTY: 0.0053426, AVERAGE_POPULARITY: 0.6331167, DIVERSITY_MEAN_INTER_LIST: 0.6674325, DIVERSITY_HERFINDAHL: 0.9667384, COVERAGE_ITEM: 0.0088598, COVERAGE_ITEM_CORRECT: 0.0058143, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.7826374, DIVERSITY_GINI: 0.0016824, SHANNON_ENTROPY: 5.3125224, RATIO_DIVERSITY_HERFINDAHL: 0.9671005, RATIO_DIVERSITY_GINI: 0.0064604, RATIO_SHANNON_ENTROPY: 0.4267204, RATIO_AVERAGE_POPULARITY: 3.2136214, RATIO_NOVELTY: 0.0314729, 
SearchBayesianSkopt: Config 57 is suboptimal. Config: {'epochs': 9, 'learning_rate': 0.003942727373922408, 'l2_reg': 0.0009652177135100053, 'dropout': 0.03806304797485533, 'total_anneal_steps': 271896, 'anneal_cap': 0.28856226800828577, 'batch_size': 512, 'encoding_size': 166, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2112154, PRECISION_RECALL_MIN_DEN: 0.2127170, RECALL: 0.0456875, MAP: 0.1028171, MAP_MIN_DEN: 0.1036205, MRR: 0.4436480, NDCG: 0.2217991, F1: 0.0751250, HIT_RATE: 0.8723685, ARHR_ALL_HITS: 0.6726126, NOVELTY: 0.0052990, AVERAGE_POPULARITY: 0.6705584, DIVERSITY_MEAN_INTER_LIST: 0.7291003, DIVERSITY_HERFINDAHL: 0.9729047, COVERAGE_ITEM: 0.0304004, COVERAGE_ITEM_CORRECT: 0.0207099, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8712821, DIVERSITY_GINI: 0.0027597, SHANNON_ENTROPY: 5.9102067, RATIO_DIVERSITY_HERFINDAHL: 0.9732691, RATIO_DIVERSITY_GINI: 0.0105975, RATIO_SHANNON_ENTROPY: 0.4747285, RATIO_AVERAGE_POPULARITY: 3.4036710, RATIO_NOVELTY: 0.0312157, 
SearchBayesianSkopt: Config 58 is suboptimal. Config: {'epochs': 29, 'learning_rate': 0.00011088027498962312, 'l2_reg': 5.641878911488444e-06, 'dropout': 0.5760478022699794, 'total_anneal_steps': 233895, 'anneal_cap': 0.3811573062657967, 'batch_size': 1024, 'encoding_size': 23, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1867234, PRECISION_RECALL_MIN_DEN: 0.1880896, RECALL: 0.0394037, MAP: 0.0905051, MAP_MIN_DEN: 0.0912788, MRR: 0.4205017, NDCG: 0.1995206, F1: 0.0650748, HIT_RATE: 0.8294579, ARHR_ALL_HITS: 0.6140239, NOVELTY: 0.0051590, AVERAGE_POPULARITY: 0.7519196, DIVERSITY_MEAN_INTER_LIST: 0.5243400, DIVERSITY_HERFINDAHL: 0.9524302, COVERAGE_ITEM: 0.0057035, COVERAGE_ITEM_CORRECT: 0.0040977, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8284249, DIVERSITY_GINI: 0.0011313, SHANNON_ENTROPY: 4.6011790, RATIO_DIVERSITY_HERFINDAHL: 0.9527869, RATIO_DIVERSITY_GINI: 0.0043444, RATIO_SHANNON_ENTROPY: 0.3695828, RATIO_AVERAGE_POPULARITY: 3.8166503, RATIO_NOVELTY: 0.0303913, 
SearchBayesianSkopt: Config 59 is suboptimal. Config: {'epochs': 7, 'learning_rate': 0.00018287380643189152, 'l2_reg': 3.569953024385779e-06, 'dropout': 0.09385394217244852, 'total_anneal_steps': 515929, 'anneal_cap': 0.4198416055320514, 'batch_size': 1024, 'encoding_size': 36, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1854691, PRECISION_RECALL_MIN_DEN: 0.1867923, RECALL: 0.0389826, MAP: 0.0900487, MAP_MIN_DEN: 0.0907863, MRR: 0.4190510, NDCG: 0.1983836, F1: 0.0644242, HIT_RATE: 0.8252036, ARHR_ALL_HITS: 0.6113048, NOVELTY: 0.0051396, AVERAGE_POPULARITY: 0.7594050, DIVERSITY_MEAN_INTER_LIST: 0.5107458, DIVERSITY_HERFINDAHL: 0.9510708, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8241758, DIVERSITY_GINI: 0.0010831, SHANNON_ENTROPY: 4.4842041, RATIO_DIVERSITY_HERFINDAHL: 0.9514271, RATIO_DIVERSITY_GINI: 0.0041593, RATIO_SHANNON_ENTROPY: 0.3601870, RATIO_AVERAGE_POPULARITY: 3.8546454, RATIO_NOVELTY: 0.0302768, 
SearchBayesianSkopt: Config 60 is suboptimal. Config: {'epochs': 15, 'learning_rate': 0.0033135038900264763, 'l2_reg': 0.00516738315587238, 'dropout': 0.04693375941659729, 'total_anneal_steps': 600000, 'anneal_cap': 0.5530895439336713, 'batch_size': 128, 'encoding_size': 1, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1873836, PRECISION_RECALL_MIN_DEN: 0.1887340, RECALL: 0.0394502, MAP: 0.0911622, MAP_MIN_DEN: 0.0919289, MRR: 0.4231644, NDCG: 0.2006087, F1: 0.0651783, HIT_RATE: 0.8313651, ARHR_ALL_HITS: 0.6184498, NOVELTY: 0.0051887, AVERAGE_POPULARITY: 0.7387038, DIVERSITY_MEAN_INTER_LIST: 0.5445776, DIVERSITY_HERFINDAHL: 0.9544538, COVERAGE_ITEM: 0.0040423, COVERAGE_ITEM_CORRECT: 0.0035993, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8303297, DIVERSITY_GINI: 0.0011934, SHANNON_ENTROPY: 4.7103686, RATIO_DIVERSITY_HERFINDAHL: 0.9548113, RATIO_DIVERSITY_GINI: 0.0045827, RATIO_SHANNON_ENTROPY: 0.3783533, RATIO_AVERAGE_POPULARITY: 3.7495686, RATIO_NOVELTY: 0.0305661, 
SearchBayesianSkopt: Config 61 is suboptimal. Config: {'epochs': 66, 'learning_rate': 0.00011049114021495677, 'l2_reg': 6.0185274955998705e-05, 'dropout': 0.5769497996099642, 'total_anneal_steps': 396544, 'anneal_cap': 0.40172716964629956, 'batch_size': 128, 'encoding_size': 485, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2249688, PRECISION_RECALL_MIN_DEN: 0.2267335, RECALL: 0.0506461, MAP: 0.1094888, MAP_MIN_DEN: 0.1104065, MRR: 0.4560851, NDCG: 0.2339403, F1: 0.0826791, HIT_RATE: 0.8948141, ARHR_ALL_HITS: 0.7031277, NOVELTY: 0.0056244, AVERAGE_POPULARITY: 0.5127250, DIVERSITY_MEAN_INTER_LIST: 0.9080669, DIVERSITY_HERFINDAHL: 0.9908000, COVERAGE_ITEM: 0.1176145, COVERAGE_ITEM_CORRECT: 0.0767484, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8936996, DIVERSITY_GINI: 0.0165340, SHANNON_ENTROPY: 8.2022502, RATIO_DIVERSITY_HERFINDAHL: 0.9911712, RATIO_DIVERSITY_GINI: 0.0634912, RATIO_SHANNON_ENTROPY: 0.6588334, RATIO_AVERAGE_POPULARITY: 2.6025284, RATIO_NOVELTY: 0.0331330, 
SearchBayesianSkopt: Config 62 is suboptimal. Config: {'epochs': 2, 'learning_rate': 0.0006336154473584342, 'l2_reg': 0.01, 'dropout': 0.06717886451104042, 'total_anneal_steps': 600000, 'anneal_cap': 0.5810827883412041, 'batch_size': 256, 'encoding_size': 1, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - results: PRECISION: 0.1846329, PRECISION_RECALL_MIN_DEN: 0.1859604, RECALL: 0.0388085, MAP: 0.0899014, MAP_MIN_DEN: 0.0906626, MRR: 0.4200658, NDCG: 0.1980284, F1: 0.0641361, HIT_RATE: 0.8242500, ARHR_ALL_HITS: 0.6115344, NOVELTY: 0.0051406, AVERAGE_POPULARITY: 0.7586002, DIVERSITY_MEAN_INTER_LIST: 0.5045572, DIVERSITY_HERFINDAHL: 0.9504520, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8232234, DIVERSITY_GINI: 0.0010689, SHANNON_ENTROPY: 4.4633243, RATIO_DIVERSITY_HERFINDAHL: 0.9508081, RATIO_DIVERSITY_GINI: 0.0041047, RATIO_SHANNON_ENTROPY: 0.3585098, RATIO_AVERAGE_POPULARITY: 3.8505603, RATIO_NOVELTY: 0.0302829, 
SearchBayesianSkopt: Config 63 is suboptimal. Config: {'epochs': 32, 'learning_rate': 5.205382675981195e-05, 'l2_reg': 3.0799427792206106e-05, 'dropout': 0.16455931070655555, 'total_anneal_steps': 153323, 'anneal_cap': 0.3644486010259942, 'batch_size': 1024, 'encoding_size': 315, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1856011, PRECISION_RECALL_MIN_DEN: 0.1869548, RECALL: 0.0390678, MAP: 0.0904019, MAP_MIN_DEN: 0.0911749, MRR: 0.4209761, NDCG: 0.1989305, F1: 0.0645485, HIT_RATE: 0.8255703, ARHR_ALL_HITS: 0.6138978, NOVELTY: 0.0051384, AVERAGE_POPULARITY: 0.7604282, DIVERSITY_MEAN_INTER_LIST: 0.5054037, DIVERSITY_HERFINDAHL: 0.9505367, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8245421, DIVERSITY_GINI: 0.0010722, SHANNON_ENTROPY: 4.4665749, RATIO_DIVERSITY_HERFINDAHL: 0.9508927, RATIO_DIVERSITY_GINI: 0.0041173, RATIO_SHANNON_ENTROPY: 0.3587709, RATIO_AVERAGE_POPULARITY: 3.8598390, RATIO_NOVELTY: 0.0302697, 
SearchBayesianSkopt: Config 64 is suboptimal. Config: {'epochs': 11, 'learning_rate': 0.003318065193070192, 'l2_reg': 0.007374765610241189, 'dropout': 0.5272885596916427, 'total_anneal_steps': 102617, 'anneal_cap': 0.006833407339513591, 'batch_size': 256, 'encoding_size': 111, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - results: PRECISION: 0.1984376, PRECISION_RECALL_MIN_DEN: 0.1999559, RECALL: 0.0437749, MAP: 0.0937695, MAP_MIN_DEN: 0.0946085, MRR: 0.4208758, NDCG: 0.2073427, F1: 0.0717269, HIT_RATE: 0.8589452, ARHR_ALL_HITS: 0.6256598, NOVELTY: 0.0055986, AVERAGE_POPULARITY: 0.5254663, DIVERSITY_MEAN_INTER_LIST: 0.8775840, DIVERSITY_HERFINDAHL: 0.9877520, COVERAGE_ITEM: 0.0540451, COVERAGE_ITEM_CORRECT: 0.0377097, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8578755, DIVERSITY_GINI: 0.0084858, SHANNON_ENTROPY: 7.4564355, RATIO_DIVERSITY_HERFINDAHL: 0.9881220, RATIO_DIVERSITY_GINI: 0.0325856, RATIO_SHANNON_ENTROPY: 0.5989270, RATIO_AVERAGE_POPULARITY: 2.6672014, RATIO_NOVELTY: 0.0329806, 
SearchBayesianSkopt: Config 65 is suboptimal. Config: {'epochs': 25, 'learning_rate': 0.001001560507551845, 'l2_reg': 0.01, 'dropout': 0.20392948667821842, 'total_anneal_steps': 252928, 'anneal_cap': 0.6, 'batch_size': 128, 'encoding_size': 224, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2181985, PRECISION_RECALL_MIN_DEN: 0.2197163, RECALL: 0.0473919, MAP: 0.1063187, MAP_MIN_DEN: 0.1071464, MRR: 0.4497965, NDCG: 0.2280221, F1: 0.0778706, HIT_RATE: 0.8833712, ARHR_ALL_HITS: 0.6885530, NOVELTY: 0.0053122, AVERAGE_POPULARITY: 0.6508810, DIVERSITY_MEAN_INTER_LIST: 0.7885155, DIVERSITY_HERFINDAHL: 0.9788458, COVERAGE_ITEM: 0.0260258, COVERAGE_ITEM_CORRECT: 0.0213744, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8822711, DIVERSITY_GINI: 0.0035349, SHANNON_ENTROPY: 6.3101394, RATIO_DIVERSITY_HERFINDAHL: 0.9792124, RATIO_DIVERSITY_GINI: 0.0135740, RATIO_SHANNON_ENTROPY: 0.5068525, RATIO_AVERAGE_POPULARITY: 3.3037912, RATIO_NOVELTY: 0.0312934, 
SearchBayesianSkopt: Config 66 is suboptimal. Config: {'epochs': 110, 'learning_rate': 0.0001372343753951698, 'l2_reg': 1e-06, 'dropout': 0.6308107689882739, 'total_anneal_steps': 428443, 'anneal_cap': 0.3201136755838761, 'batch_size': 512, 'encoding_size': 1, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1858725, PRECISION_RECALL_MIN_DEN: 0.1872163, RECALL: 0.0390944, MAP: 0.0904162, MAP_MIN_DEN: 0.0911866, MRR: 0.4201446, NDCG: 0.1989841, F1: 0.0646012, HIT_RATE: 0.8252036, ARHR_ALL_HITS: 0.6133767, NOVELTY: 0.0051385, AVERAGE_POPULARITY: 0.7602976, DIVERSITY_MEAN_INTER_LIST: 0.5056100, DIVERSITY_HERFINDAHL: 0.9505573, COVERAGE_ITEM: 0.0021042, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8241758, DIVERSITY_GINI: 0.0010732, SHANNON_ENTROPY: 4.4652236, RATIO_DIVERSITY_HERFINDAHL: 0.9509134, RATIO_DIVERSITY_GINI: 0.0041212, RATIO_SHANNON_ENTROPY: 0.3586624, RATIO_AVERAGE_POPULARITY: 3.8591763, RATIO_NOVELTY: 0.0302706, 
SearchBayesianSkopt: Config 67 is suboptimal. Config: {'epochs': 3, 'learning_rate': 0.0009762656499057003, 'l2_reg': 3.452132644003487e-05, 'dropout': 0.6303537020864352, 'total_anneal_steps': 494559, 'anneal_cap': 0.13921022682428166, 'batch_size': 128, 'encoding_size': 244, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2155578, PRECISION_RECALL_MIN_DEN: 0.2173529, RECALL: 0.0492993, MAP: 0.1020408, MAP_MIN_DEN: 0.1029542, MRR: 0.4372985, NDCG: 0.2227810, F1: 0.0802459, HIT_RATE: 0.8901196, ARHR_ALL_HITS: 0.6653969, NOVELTY: 0.0057628, AVERAGE_POPULARITY: 0.4613379, DIVERSITY_MEAN_INTER_LIST: 0.9265214, DIVERSITY_HERFINDAHL: 0.9926453, COVERAGE_ITEM: 0.1372723, COVERAGE_ITEM_CORRECT: 0.0872141, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8890110, DIVERSITY_GINI: 0.0211126, SHANNON_ENTROPY: 8.5652869, RATIO_DIVERSITY_HERFINDAHL: 0.9930172, RATIO_DIVERSITY_GINI: 0.0810731, RATIO_SHANNON_ENTROPY: 0.6879938, RATIO_AVERAGE_POPULARITY: 2.3416937, RATIO_NOVELTY: 0.0339480, 
SearchBayesianSkopt: Config 68 is suboptimal. Config: {'epochs': 30, 'learning_rate': 0.0002712175765931521, 'l2_reg': 0.01, 'dropout': 0.2702123898683568, 'total_anneal_steps': 100000, 'anneal_cap': 0.6, 'batch_size': 128, 'encoding_size': 222, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2111347, PRECISION_RECALL_MIN_DEN: 0.2126991, RECALL: 0.0461991, MAP: 0.1022181, MAP_MIN_DEN: 0.1030885, MRR: 0.4417018, NDCG: 0.2211866, F1: 0.0758099, HIT_RATE: 0.8764762, ARHR_ALL_HITS: 0.6691292, NOVELTY: 0.0054484, AVERAGE_POPULARITY: 0.5992409, DIVERSITY_MEAN_INTER_LIST: 0.8215912, DIVERSITY_HERFINDAHL: 0.9821531, COVERAGE_ITEM: 0.0427488, COVERAGE_ITEM_CORRECT: 0.0311202, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8753846, DIVERSITY_GINI: 0.0053338, SHANNON_ENTROPY: 6.7865297, RATIO_DIVERSITY_HERFINDAHL: 0.9825210, RATIO_DIVERSITY_GINI: 0.0204818, RATIO_SHANNON_ENTROPY: 0.5451178, RATIO_AVERAGE_POPULARITY: 3.0416722, RATIO_NOVELTY: 0.0320961, 
SearchBayesianSkopt: Config 69 is suboptimal. Config: {'epochs': 82, 'learning_rate': 0.00026942333391187436, 'l2_reg': 0.00046252557044987016, 'dropout': 0.27048073068724604, 'total_anneal_steps': 499116, 'anneal_cap': 0.6, 'batch_size': 1024, 'encoding_size': 1, 'next_layer_size_multiplier': 9, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1857772, PRECISION_RECALL_MIN_DEN: 0.1871193, RECALL: 0.0390442, MAP: 0.0901478, MAP_MIN_DEN: 0.0909206, MRR: 0.4194767, NDCG: 0.1986689, F1: 0.0645270, HIT_RATE: 0.8260104, ARHR_ALL_HITS: 0.6119593, NOVELTY: 0.0051401, AVERAGE_POPULARITY: 0.7600702, DIVERSITY_MEAN_INTER_LIST: 0.5048278, DIVERSITY_HERFINDAHL: 0.9504791, COVERAGE_ITEM: 0.0031563, COVERAGE_ITEM_CORRECT: 0.0019381, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8249817, DIVERSITY_GINI: 0.0010706, SHANNON_ENTROPY: 4.4663850, RATIO_DIVERSITY_HERFINDAHL: 0.9508351, RATIO_DIVERSITY_GINI: 0.0041112, RATIO_SHANNON_ENTROPY: 0.3587557, RATIO_AVERAGE_POPULARITY: 3.8580217, RATIO_NOVELTY: 0.0302799, 
SearchBayesianSkopt: Config 70 is suboptimal. Config: {'epochs': 66, 'learning_rate': 1.1117573312358883e-06, 'l2_reg': 4.579700440075388e-06, 'dropout': 0.1975305749265792, 'total_anneal_steps': 544710, 'anneal_cap': 0.33951142929345, 'batch_size': 256, 'encoding_size': 267, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1859385, PRECISION_RECALL_MIN_DEN: 0.1872495, RECALL: 0.0391156, MAP: 0.0903883, MAP_MIN_DEN: 0.0911446, MRR: 0.4199810, NDCG: 0.1989428, F1: 0.0646342, HIT_RATE: 0.8261571, ARHR_ALL_HITS: 0.6130723, NOVELTY: 0.0051387, AVERAGE_POPULARITY: 0.7602159, DIVERSITY_MEAN_INTER_LIST: 0.5080316, DIVERSITY_HERFINDAHL: 0.9507994, COVERAGE_ITEM: 0.0022703, COVERAGE_ITEM_CORRECT: 0.0021596, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8251282, DIVERSITY_GINI: 0.0010773, SHANNON_ENTROPY: 4.4814875, RATIO_DIVERSITY_HERFINDAHL: 0.9511556, RATIO_DIVERSITY_GINI: 0.0041369, RATIO_SHANNON_ENTROPY: 0.3599687, RATIO_AVERAGE_POPULARITY: 3.8587613, RATIO_NOVELTY: 0.0302713, 
SearchBayesianSkopt: Config 71 is suboptimal. Config: {'epochs': 39, 'learning_rate': 1.5644441195846538e-06, 'l2_reg': 0.01, 'dropout': 0.7989938997349766, 'total_anneal_steps': 142149, 'anneal_cap': 0.19968483903137046, 'batch_size': 256, 'encoding_size': 512, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1858725, PRECISION_RECALL_MIN_DEN: 0.1872341, RECALL: 0.0391034, MAP: 0.0902679, MAP_MIN_DEN: 0.0910250, MRR: 0.4203202, NDCG: 0.1988797, F1: 0.0646136, HIT_RATE: 0.8261571, ARHR_ALL_HITS: 0.6129185, NOVELTY: 0.0051391, AVERAGE_POPULARITY: 0.7598189, DIVERSITY_MEAN_INTER_LIST: 0.5084326, DIVERSITY_HERFINDAHL: 0.9508395, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0020488, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8251282, DIVERSITY_GINI: 0.0010787, SHANNON_ENTROPY: 4.4776802, RATIO_DIVERSITY_HERFINDAHL: 0.9511957, RATIO_DIVERSITY_GINI: 0.0041423, RATIO_SHANNON_ENTROPY: 0.3596629, RATIO_AVERAGE_POPULARITY: 3.8567464, RATIO_NOVELTY: 0.0302738, 
SearchBayesianSkopt: Config 72 is suboptimal. Config: {'epochs': 26, 'learning_rate': 0.00026519688726165264, 'l2_reg': 1e-06, 'dropout': 0.2702175481176447, 'total_anneal_steps': 162551, 'anneal_cap': 0.06231373911350374, 'batch_size': 256, 'encoding_size': 1, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1859092, PRECISION_RECALL_MIN_DEN: 0.1872506, RECALL: 0.0390953, MAP: 0.0903163, MAP_MIN_DEN: 0.0910910, MRR: 0.4195610, NDCG: 0.1988440, F1: 0.0646047, HIT_RATE: 0.8260838, ARHR_ALL_HITS: 0.6125114, NOVELTY: 0.0051383, AVERAGE_POPULARITY: 0.7605213, DIVERSITY_MEAN_INTER_LIST: 0.5046438, DIVERSITY_HERFINDAHL: 0.9504607, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0020488, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8250549, DIVERSITY_GINI: 0.0010697, SHANNON_ENTROPY: 4.4631707, RATIO_DIVERSITY_HERFINDAHL: 0.9508167, RATIO_DIVERSITY_GINI: 0.0041075, RATIO_SHANNON_ENTROPY: 0.3584975, RATIO_AVERAGE_POPULARITY: 3.8603117, RATIO_NOVELTY: 0.0302691, 
SearchBayesianSkopt: Config 73 is suboptimal. Config: {'epochs': 37, 'learning_rate': 0.0038329988684359263, 'l2_reg': 0.00017120418526638746, 'dropout': 0.03819647527788603, 'total_anneal_steps': 216462, 'anneal_cap': 0.34831706664785483, 'batch_size': 512, 'encoding_size': 16, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2116775, PRECISION_RECALL_MIN_DEN: 0.2130912, RECALL: 0.0450080, MAP: 0.1039204, MAP_MIN_DEN: 0.1047133, MRR: 0.4477995, NDCG: 0.2230719, F1: 0.0742324, HIT_RATE: 0.8684075, ARHR_ALL_HITS: 0.6788780, NOVELTY: 0.0052563, AVERAGE_POPULARITY: 0.6931848, DIVERSITY_MEAN_INTER_LIST: 0.7063248, DIVERSITY_HERFINDAHL: 0.9706273, COVERAGE_ITEM: 0.0382081, COVERAGE_ITEM_CORRECT: 0.0250844, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8673260, DIVERSITY_GINI: 0.0028572, SHANNON_ENTROPY: 5.8342685, RATIO_DIVERSITY_HERFINDAHL: 0.9709909, RATIO_DIVERSITY_GINI: 0.0109716, RATIO_SHANNON_ENTROPY: 0.4686288, RATIO_AVERAGE_POPULARITY: 3.5185198, RATIO_NOVELTY: 0.0309644, 
SearchBayesianSkopt: Config 74 is suboptimal. Config: {'epochs': 15, 'learning_rate': 0.003342419646997536, 'l2_reg': 0.01, 'dropout': 0.04884713398085384, 'total_anneal_steps': 600000, 'anneal_cap': 0.04310922324747623, 'batch_size': 128, 'encoding_size': 188, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2053326, PRECISION_RECALL_MIN_DEN: 0.2068308, RECALL: 0.0443424, MAP: 0.0990298, MAP_MIN_DEN: 0.0998620, MRR: 0.4327456, NDCG: 0.2153712, F1: 0.0729343, HIT_RATE: 0.8624661, ARHR_ALL_HITS: 0.6519310, NOVELTY: 0.0053701, AVERAGE_POPULARITY: 0.6420066, DIVERSITY_MEAN_INTER_LIST: 0.7456472, DIVERSITY_HERFINDAHL: 0.9745592, COVERAGE_ITEM: 0.0232571, COVERAGE_ITEM_CORRECT: 0.0183288, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8613919, DIVERSITY_GINI: 0.0030111, SHANNON_ENTROPY: 6.0456133, RATIO_DIVERSITY_HERFINDAHL: 0.9749243, RATIO_DIVERSITY_GINI: 0.0115626, RATIO_SHANNON_ENTROPY: 0.4856048, RATIO_AVERAGE_POPULARITY: 3.2587456, RATIO_NOVELTY: 0.0316347, 
SearchBayesianSkopt: Config 75 is suboptimal. Config: {'epochs': 24, 'learning_rate': 0.0005851367333795395, 'l2_reg': 3.724592048665644e-05, 'dropout': 0.7891838409095755, 'total_anneal_steps': 575936, 'anneal_cap': 0.09118403703232794, 'batch_size': 512, 'encoding_size': 48, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2131372, PRECISION_RECALL_MIN_DEN: 0.2146161, RECALL: 0.0468655, MAP: 0.1023368, MAP_MIN_DEN: 0.1031031, MRR: 0.4378582, NDCG: 0.2216958, F1: 0.0768359, HIT_RATE: 0.8781633, ARHR_ALL_HITS: 0.6668008, NOVELTY: 0.0055247, AVERAGE_POPULARITY: 0.5613007, DIVERSITY_MEAN_INTER_LIST: 0.8663927, DIVERSITY_HERFINDAHL: 0.9866329, COVERAGE_ITEM: 0.0599701, COVERAGE_ITEM_CORRECT: 0.0369345, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8770696, DIVERSITY_GINI: 0.0079404, SHANNON_ENTROPY: 7.3348962, RATIO_DIVERSITY_HERFINDAHL: 0.9870025, RATIO_DIVERSITY_GINI: 0.0304915, RATIO_SHANNON_ENTROPY: 0.5891645, RATIO_AVERAGE_POPULARITY: 2.8490926, RATIO_NOVELTY: 0.0325457, 
SearchBayesianSkopt: Config 76 is suboptimal. Config: {'epochs': 9, 'learning_rate': 0.003786623205989808, 'l2_reg': 0.0039941255668039435, 'dropout': 0.039004981166367164, 'total_anneal_steps': 488492, 'anneal_cap': 0.42648076670551943, 'batch_size': 256, 'encoding_size': 16, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2021419, PRECISION_RECALL_MIN_DEN: 0.2036202, RECALL: 0.0434976, MAP: 0.0978273, MAP_MIN_DEN: 0.0986510, MRR: 0.4310956, NDCG: 0.2128529, F1: 0.0715901, HIT_RATE: 0.8556444, ARHR_ALL_HITS: 0.6465837, NOVELTY: 0.0052449, AVERAGE_POPULARITY: 0.6931530, DIVERSITY_MEAN_INTER_LIST: 0.6898475, DIVERSITY_HERFINDAHL: 0.9689797, COVERAGE_ITEM: 0.0144526, COVERAGE_ITEM_CORRECT: 0.0111856, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8545788, DIVERSITY_GINI: 0.0019718, SHANNON_ENTROPY: 5.5260742, RATIO_DIVERSITY_HERFINDAHL: 0.9693427, RATIO_DIVERSITY_GINI: 0.0075717, RATIO_SHANNON_ENTROPY: 0.4438736, RATIO_AVERAGE_POPULARITY: 3.5183585, RATIO_NOVELTY: 0.0308969, 
SearchBayesianSkopt: Config 77 is suboptimal. Config: {'epochs': 15, 'learning_rate': 0.00011077521923466068, 'l2_reg': 4.022296246830231e-05, 'dropout': 0.576686279998136, 'total_anneal_steps': 260301, 'anneal_cap': 0.5509306807011105, 'batch_size': 256, 'encoding_size': 301, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2158439, PRECISION_RECALL_MIN_DEN: 0.2175567, RECALL: 0.0484888, MAP: 0.1022716, MAP_MIN_DEN: 0.1031504, MRR: 0.4353246, NDCG: 0.2226878, F1: 0.0791882, HIT_RATE: 0.8858652, ARHR_ALL_HITS: 0.6642170, NOVELTY: 0.0056313, AVERAGE_POPULARITY: 0.5148701, DIVERSITY_MEAN_INTER_LIST: 0.8993069, DIVERSITY_HERFINDAHL: 0.9899241, COVERAGE_ITEM: 0.1077025, COVERAGE_ITEM_CORRECT: 0.0648430, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8847619, DIVERSITY_GINI: 0.0132711, SHANNON_ENTROPY: 7.9444351, RATIO_DIVERSITY_HERFINDAHL: 0.9902949, RATIO_DIVERSITY_GINI: 0.0509612, RATIO_SHANNON_ENTROPY: 0.6381248, RATIO_AVERAGE_POPULARITY: 2.6134166, RATIO_NOVELTY: 0.0331734, 
SearchBayesianSkopt: Config 78 is suboptimal. Config: {'epochs': 233, 'learning_rate': 3.3855161135351337e-06, 'l2_reg': 0.0002457116690185844, 'dropout': 0.6722957669146895, 'total_anneal_steps': 440950, 'anneal_cap': 0.279563038349427, 'batch_size': 512, 'encoding_size': 391, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1859165, PRECISION_RECALL_MIN_DEN: 0.1872602, RECALL: 0.0391881, MAP: 0.0904992, MAP_MIN_DEN: 0.0912782, MRR: 0.4222002, NDCG: 0.1992468, F1: 0.0647319, HIT_RATE: 0.8267439, ARHR_ALL_HITS: 0.6149725, NOVELTY: 0.0051393, AVERAGE_POPULARITY: 0.7596484, DIVERSITY_MEAN_INTER_LIST: 0.5057066, DIVERSITY_HERFINDAHL: 0.9505670, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8257143, DIVERSITY_GINI: 0.0010726, SHANNON_ENTROPY: 4.4670346, RATIO_DIVERSITY_HERFINDAHL: 0.9509230, RATIO_DIVERSITY_GINI: 0.0041186, RATIO_SHANNON_ENTROPY: 0.3588078, RATIO_AVERAGE_POPULARITY: 3.8558806, RATIO_NOVELTY: 0.0302753, 
SearchBayesianSkopt: Config 79 is suboptimal. Config: {'epochs': 88, 'learning_rate': 1.2173768904760653e-06, 'l2_reg': 0.0002672526076250864, 'dropout': 0.7488756585746927, 'total_anneal_steps': 131141, 'anneal_cap': 0.38179840001101356, 'batch_size': 512, 'encoding_size': 402, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1855351, PRECISION_RECALL_MIN_DEN: 0.1868330, RECALL: 0.0389370, MAP: 0.0902453, MAP_MIN_DEN: 0.0910110, MRR: 0.4205093, NDCG: 0.1987493, F1: 0.0643659, HIT_RATE: 0.8253503, ARHR_ALL_HITS: 0.6131617, NOVELTY: 0.0051390, AVERAGE_POPULARITY: 0.7599158, DIVERSITY_MEAN_INTER_LIST: 0.5087905, DIVERSITY_HERFINDAHL: 0.9508753, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8243223, DIVERSITY_GINI: 0.0010798, SHANNON_ENTROPY: 4.4828632, RATIO_DIVERSITY_HERFINDAHL: 0.9512315, RATIO_DIVERSITY_GINI: 0.0041466, RATIO_SHANNON_ENTROPY: 0.3600792, RATIO_AVERAGE_POPULARITY: 3.8572382, RATIO_NOVELTY: 0.0302733, 
SearchBayesianSkopt: Config 80 is suboptimal. Config: {'epochs': 4, 'learning_rate': 0.0009702609880336174, 'l2_reg': 7.64635453943885e-05, 'dropout': 0.3966929413523585, 'total_anneal_steps': 580330, 'anneal_cap': 0.05055784131870123, 'batch_size': 128, 'encoding_size': 430, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2154111, PRECISION_RECALL_MIN_DEN: 0.2171709, RECALL: 0.0497082, MAP: 0.1018753, MAP_MIN_DEN: 0.1028187, MRR: 0.4344334, NDCG: 0.2221957, F1: 0.0807764, HIT_RATE: 0.8888726, ARHR_ALL_HITS: 0.6624555, NOVELTY: 0.0058500, AVERAGE_POPULARITY: 0.4394279, DIVERSITY_MEAN_INTER_LIST: 0.9355035, DIVERSITY_HERFINDAHL: 0.9935435, COVERAGE_ITEM: 0.1822914, COVERAGE_ITEM_CORRECT: 0.1046016, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8877656, DIVERSITY_GINI: 0.0274713, SHANNON_ENTROPY: 8.8700088, RATIO_DIVERSITY_HERFINDAHL: 0.9939157, RATIO_DIVERSITY_GINI: 0.1054905, RATIO_SHANNON_ENTROPY: 0.7124701, RATIO_AVERAGE_POPULARITY: 2.2304812, RATIO_NOVELTY: 0.0344620, 
SearchBayesianSkopt: Config 81 is suboptimal. Config: {'epochs': 37, 'learning_rate': 0.007198046267841004, 'l2_reg': 0.004544921952634702, 'dropout': 0.7231505520136214, 'total_anneal_steps': 557519, 'anneal_cap': 0.04504406079460994, 'batch_size': 1024, 'encoding_size': 300, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2288858, PRECISION_RECALL_MIN_DEN: 0.2307228, RECALL: 0.0519951, MAP: 0.1116280, MAP_MIN_DEN: 0.1126268, MRR: 0.4578335, NDCG: 0.2375895, F1: 0.0847402, HIT_RATE: 0.9011223, ARHR_ALL_HITS: 0.7122704, NOVELTY: 0.0055879, AVERAGE_POPULARITY: 0.5153403, DIVERSITY_MEAN_INTER_LIST: 0.9134470, DIVERSITY_HERFINDAHL: 0.9913380, COVERAGE_ITEM: 0.0749211, COVERAGE_ITEM_CORRECT: 0.0567584, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.9000000, DIVERSITY_GINI: 0.0131693, SHANNON_ENTROPY: 8.0543660, RATIO_DIVERSITY_HERFINDAHL: 0.9917093, RATIO_DIVERSITY_GINI: 0.0505705, RATIO_SHANNON_ENTROPY: 0.6469548, RATIO_AVERAGE_POPULARITY: 2.6158035, RATIO_NOVELTY: 0.0329175, 
SearchBayesianSkopt: Config 82 is suboptimal. Config: {'epochs': 3, 'learning_rate': 0.0009718593980792829, 'l2_reg': 4.41111409229345e-05, 'dropout': 0.3966601781415497, 'total_anneal_steps': 100000, 'anneal_cap': 0.0, 'batch_size': 256, 'encoding_size': 435, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1701093, PRECISION_RECALL_MIN_DEN: 0.1713390, RECALL: 0.0353848, MAP: 0.0820211, MAP_MIN_DEN: 0.0827302, MRR: 0.4049024, NDCG: 0.1843128, F1: 0.0585835, HIT_RATE: 0.8016577, ARHR_ALL_HITS: 0.5738027, NOVELTY: 0.0051920, AVERAGE_POPULARITY: 0.7174670, DIVERSITY_MEAN_INTER_LIST: 0.4825622, DIVERSITY_HERFINDAHL: 0.9482527, COVERAGE_ITEM: 0.0025472, COVERAGE_ITEM_CORRECT: 0.0019381, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8006593, DIVERSITY_GINI: 0.0010220, SHANNON_ENTROPY: 4.4009165, RATIO_DIVERSITY_HERFINDAHL: 0.9486079, RATIO_DIVERSITY_GINI: 0.0039246, RATIO_SHANNON_ENTROPY: 0.3534970, RATIO_AVERAGE_POPULARITY: 3.6417731, RATIO_NOVELTY: 0.0305858, 
SearchBayesianSkopt: Config 83 is suboptimal. Config: {'epochs': 11, 'learning_rate': 0.005353927456497023, 'l2_reg': 0.00016274140015372612, 'dropout': 0.35583170213159476, 'total_anneal_steps': 161961, 'anneal_cap': 0.0, 'batch_size': 128, 'encoding_size': 34, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2258710, PRECISION_RECALL_MIN_DEN: 0.2275938, RECALL: 0.0511516, MAP: 0.1086724, MAP_MIN_DEN: 0.1095683, MRR: 0.4477510, NDCG: 0.2329201, F1: 0.0834132, HIT_RATE: 0.8958410, ARHR_ALL_HITS: 0.6947539, NOVELTY: 0.0056617, AVERAGE_POPULARITY: 0.5026592, DIVERSITY_MEAN_INTER_LIST: 0.9122129, DIVERSITY_HERFINDAHL: 0.9912146, COVERAGE_ITEM: 0.1612492, COVERAGE_ITEM_CORRECT: 0.0942466, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8947253, DIVERSITY_GINI: 0.0202800, SHANNON_ENTROPY: 8.3805955, RATIO_DIVERSITY_HERFINDAHL: 0.9915859, RATIO_DIVERSITY_GINI: 0.0778757, RATIO_SHANNON_ENTROPY: 0.6731587, RATIO_AVERAGE_POPULARITY: 2.5514354, RATIO_NOVELTY: 0.0333523, 
SearchBayesianSkopt: Config 84 is suboptimal. Config: {'epochs': 47, 'learning_rate': 4.819964193349625e-05, 'l2_reg': 0.0003350097731629681, 'dropout': 0.10355692119117695, 'total_anneal_steps': 100000, 'anneal_cap': 0.3017473150801526, 'batch_size': 1024, 'encoding_size': 225, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1859752, PRECISION_RECALL_MIN_DEN: 0.1873065, RECALL: 0.0391426, MAP: 0.0903940, MAP_MIN_DEN: 0.0911659, MRR: 0.4200967, NDCG: 0.1989942, F1: 0.0646733, HIT_RATE: 0.8265239, ARHR_ALL_HITS: 0.6132109, NOVELTY: 0.0051385, AVERAGE_POPULARITY: 0.7603638, DIVERSITY_MEAN_INTER_LIST: 0.5057431, DIVERSITY_HERFINDAHL: 0.9505706, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8254945, DIVERSITY_GINI: 0.0010737, SHANNON_ENTROPY: 4.4674321, RATIO_DIVERSITY_HERFINDAHL: 0.9509267, RATIO_DIVERSITY_GINI: 0.0041232, RATIO_SHANNON_ENTROPY: 0.3588398, RATIO_AVERAGE_POPULARITY: 3.8595123, RATIO_NOVELTY: 0.0302702, 
SearchBayesianSkopt: Config 85 is suboptimal. Config: {'epochs': 4, 'learning_rate': 0.00018818219443478623, 'l2_reg': 0.003181861716313898, 'dropout': 0.09341238531761631, 'total_anneal_steps': 347297, 'anneal_cap': 0.6, 'batch_size': 256, 'encoding_size': 452, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1861586, PRECISION_RECALL_MIN_DEN: 0.1874989, RECALL: 0.0392225, MAP: 0.0906324, MAP_MIN_DEN: 0.0914025, MRR: 0.4224674, NDCG: 0.1994053, F1: 0.0647934, HIT_RATE: 0.8271107, ARHR_ALL_HITS: 0.6153597, NOVELTY: 0.0051390, AVERAGE_POPULARITY: 0.7599336, DIVERSITY_MEAN_INTER_LIST: 0.5050575, DIVERSITY_HERFINDAHL: 0.9505020, COVERAGE_ITEM: 0.0023257, COVERAGE_ITEM_CORRECT: 0.0021596, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8260806, DIVERSITY_GINI: 0.0010713, SHANNON_ENTROPY: 4.4649635, RATIO_DIVERSITY_HERFINDAHL: 0.9508581, RATIO_DIVERSITY_GINI: 0.0041137, RATIO_SHANNON_ENTROPY: 0.3586415, RATIO_AVERAGE_POPULARITY: 3.8573284, RATIO_NOVELTY: 0.0302733, 
SearchBayesianSkopt: Config 86 is suboptimal. Config: {'epochs': 35, 'learning_rate': 5.989695246260129e-05, 'l2_reg': 5.1250566643574706e-06, 'dropout': 0.16416901441781726, 'total_anneal_steps': 600000, 'anneal_cap': 0.0, 'batch_size': 512, 'encoding_size': 1, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1858432, PRECISION_RECALL_MIN_DEN: 0.1871878, RECALL: 0.0391172, MAP: 0.0903951, MAP_MIN_DEN: 0.0911582, MRR: 0.4209761, NDCG: 0.1990322, F1: 0.0646307, HIT_RATE: 0.8257904, ARHR_ALL_HITS: 0.6138820, NOVELTY: 0.0051383, AVERAGE_POPULARITY: 0.7605221, DIVERSITY_MEAN_INTER_LIST: 0.5045873, DIVERSITY_HERFINDAHL: 0.9504550, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0019935, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8247619, DIVERSITY_GINI: 0.0010694, SHANNON_ENTROPY: 4.4627997, RATIO_DIVERSITY_HERFINDAHL: 0.9508111, RATIO_DIVERSITY_GINI: 0.0041066, RATIO_SHANNON_ENTROPY: 0.3584677, RATIO_AVERAGE_POPULARITY: 3.8603158, RATIO_NOVELTY: 0.0302691, 
SearchBayesianSkopt: Config 87 is suboptimal. Config: {'epochs': 12, 'learning_rate': 0.003223478645720276, 'l2_reg': 0.0009185755007168525, 'dropout': 0.049127776869754974, 'total_anneal_steps': 600000, 'anneal_cap': 0.41336569805992274, 'batch_size': 512, 'encoding_size': 143, 'next_layer_size_multiplier': 4, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - results: PRECISION: 0.2069757, PRECISION_RECALL_MIN_DEN: 0.2084611, RECALL: 0.0449751, MAP: 0.0996678, MAP_MIN_DEN: 0.1004964, MRR: 0.4323801, NDCG: 0.2166781, F1: 0.0738935, HIT_RATE: 0.8680408, ARHR_ALL_HITS: 0.6545924, NOVELTY: 0.0053192, AVERAGE_POPULARITY: 0.6628694, DIVERSITY_MEAN_INTER_LIST: 0.7382884, DIVERSITY_HERFINDAHL: 0.9738234, COVERAGE_ITEM: 0.0342212, COVERAGE_ITEM_CORRECT: 0.0227034, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8669597, DIVERSITY_GINI: 0.0030910, SHANNON_ENTROPY: 6.0184521, RATIO_DIVERSITY_HERFINDAHL: 0.9741882, RATIO_DIVERSITY_GINI: 0.0118695, RATIO_SHANNON_ENTROPY: 0.4834231, RATIO_AVERAGE_POPULARITY: 3.3646427, RATIO_NOVELTY: 0.0313350, 
SearchBayesianSkopt: Config 88 is suboptimal. Config: {'epochs': 55, 'learning_rate': 0.0005304419335794155, 'l2_reg': 3.139790338757238e-05, 'dropout': 0.5412961368183575, 'total_anneal_steps': 127800, 'anneal_cap': 0.010531509566480982, 'batch_size': 1024, 'encoding_size': 321, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2223575, PRECISION_RECALL_MIN_DEN: 0.2241303, RECALL: 0.0498124, MAP: 0.1080139, MAP_MIN_DEN: 0.1089420, MRR: 0.4522972, NDCG: 0.2314019, F1: 0.0813915, HIT_RATE: 0.8917333, ARHR_ALL_HITS: 0.6956091, NOVELTY: 0.0056020, AVERAGE_POPULARITY: 0.5243885, DIVERSITY_MEAN_INTER_LIST: 0.9003885, DIVERSITY_HERFINDAHL: 0.9900322, COVERAGE_ITEM: 0.1017221, COVERAGE_ITEM_CORRECT: 0.0677778, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8906227, DIVERSITY_GINI: 0.0139594, SHANNON_ENTROPY: 7.9903326, RATIO_DIVERSITY_HERFINDAHL: 0.9904031, RATIO_DIVERSITY_GINI: 0.0536043, RATIO_SHANNON_ENTROPY: 0.6418115, RATIO_AVERAGE_POPULARITY: 2.6617309, RATIO_NOVELTY: 0.0330009, 
SearchBayesianSkopt: Config 89 is suboptimal. Config: {'epochs': 68, 'learning_rate': 1.1104740974330513e-06, 'l2_reg': 1.576667776529881e-05, 'dropout': 0.19769393911336552, 'total_anneal_steps': 380599, 'anneal_cap': 0.44625224405997777, 'batch_size': 256, 'encoding_size': 512, 'next_layer_size_multiplier': 3, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.1856965, PRECISION_RECALL_MIN_DEN: 0.1869768, RECALL: 0.0388690, MAP: 0.0903741, MAP_MIN_DEN: 0.0911391, MRR: 0.4202666, NDCG: 0.1988013, F1: 0.0642828, HIT_RATE: 0.8246167, ARHR_ALL_HITS: 0.6129888, NOVELTY: 0.0051392, AVERAGE_POPULARITY: 0.7597540, DIVERSITY_MEAN_INTER_LIST: 0.5097107, DIVERSITY_HERFINDAHL: 0.9509673, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8235897, DIVERSITY_GINI: 0.0010831, SHANNON_ENTROPY: 4.4810049, RATIO_DIVERSITY_HERFINDAHL: 0.9513236, RATIO_DIVERSITY_GINI: 0.0041593, RATIO_SHANNON_ENTROPY: 0.3599300, RATIO_AVERAGE_POPULARITY: 3.8564167, RATIO_NOVELTY: 0.0302743, 
SearchBayesianSkopt: Config 90 is suboptimal. Config: {'epochs': 3, 'learning_rate': 0.0001111139421866305, 'l2_reg': 1.4914819547988372e-05, 'dropout': 0.576638187011615, 'total_anneal_steps': 350902, 'anneal_cap': 0.5356004661974626, 'batch_size': 512, 'encoding_size': 188, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.1857552, PRECISION_RECALL_MIN_DEN: 0.1870149, RECALL: 0.0389118, MAP: 0.0903260, MAP_MIN_DEN: 0.0910713, MRR: 0.4196442, NDCG: 0.1987391, F1: 0.0643447, HIT_RATE: 0.8243233, ARHR_ALL_HITS: 0.6126120, NOVELTY: 0.0051396, AVERAGE_POPULARITY: 0.7594286, DIVERSITY_MEAN_INTER_LIST: 0.5061435, DIVERSITY_HERFINDAHL: 0.9506106, COVERAGE_ITEM: 0.0022703, COVERAGE_ITEM_CORRECT: 0.0022150, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8232967, DIVERSITY_GINI: 0.0010741, SHANNON_ENTROPY: 4.4702049, RATIO_DIVERSITY_HERFINDAHL: 0.9509667, RATIO_DIVERSITY_GINI: 0.0041245, RATIO_SHANNON_ENTROPY: 0.3590625, RATIO_AVERAGE_POPULARITY: 3.8547652, RATIO_NOVELTY: 0.0302766, 
SearchBayesianSkopt: Config 91 is suboptimal. Config: {'epochs': 20, 'learning_rate': 7.653479073359108e-05, 'l2_reg': 7.3027939288384235e-06, 'dropout': 0.6627829174657808, 'total_anneal_steps': 240906, 'anneal_cap': 0.019841316114180715, 'batch_size': 1024, 'encoding_size': 393, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1857992, PRECISION_RECALL_MIN_DEN: 0.1871810, RECALL: 0.0391650, MAP: 0.0904225, MAP_MIN_DEN: 0.0911956, MRR: 0.4209727, NDCG: 0.1990430, F1: 0.0646932, HIT_RATE: 0.8260838, ARHR_ALL_HITS: 0.6139431, NOVELTY: 0.0051385, AVERAGE_POPULARITY: 0.7603724, DIVERSITY_MEAN_INTER_LIST: 0.5059140, DIVERSITY_HERFINDAHL: 0.9505877, COVERAGE_ITEM: 0.0022150, COVERAGE_ITEM_CORRECT: 0.0021042, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8250549, DIVERSITY_GINI: 0.0010740, SHANNON_ENTROPY: 4.4679753, RATIO_DIVERSITY_HERFINDAHL: 0.9509438, RATIO_DIVERSITY_GINI: 0.0041242, RATIO_SHANNON_ENTROPY: 0.3588834, RATIO_AVERAGE_POPULARITY: 3.8595558, RATIO_NOVELTY: 0.0302701, 
SearchBayesianSkopt: Config 92 is suboptimal. Config: {'epochs': 76, 'learning_rate': 0.00011070720291691117, 'l2_reg': 5.3660030303956946e-05, 'dropout': 0.5766353657253288, 'total_anneal_steps': 193876, 'anneal_cap': 0.19011323721578802, 'batch_size': 256, 'encoding_size': 365, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2220274, PRECISION_RECALL_MIN_DEN: 0.2237428, RECALL: 0.0493491, MAP: 0.1078643, MAP_MIN_DEN: 0.1087723, MRR: 0.4521034, NDCG: 0.2310841, F1: 0.0807503, HIT_RATE: 0.8904863, ARHR_ALL_HITS: 0.6949098, NOVELTY: 0.0055449, AVERAGE_POPULARITY: 0.5483774, DIVERSITY_MEAN_INTER_LIST: 0.8833297, DIVERSITY_HERFINDAHL: 0.9883265, COVERAGE_ITEM: 0.0812337, COVERAGE_ITEM_CORRECT: 0.0559832, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8893773, DIVERSITY_GINI: 0.0110083, SHANNON_ENTROPY: 7.6853234, RATIO_DIVERSITY_HERFINDAHL: 0.9886967, RATIO_DIVERSITY_GINI: 0.0422721, RATIO_SHANNON_ENTROPY: 0.6173120, RATIO_AVERAGE_POPULARITY: 2.7834956, RATIO_NOVELTY: 0.0326643, 
SearchBayesianSkopt: Config 93 is suboptimal. Config: {'epochs': 27, 'learning_rate': 0.0002744538692802073, 'l2_reg': 0.008917546738835767, 'dropout': 0.2705676578381943, 'total_anneal_steps': 100000, 'anneal_cap': 0.37277969594262916, 'batch_size': 128, 'encoding_size': 122, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results: PRECISION: 0.2054427, PRECISION_RECALL_MIN_DEN: 0.2069767, RECALL: 0.0444391, MAP: 0.0997930, MAP_MIN_DEN: 0.1006444, MRR: 0.4376312, NDCG: 0.2164302, F1: 0.0730721, HIT_RATE: 0.8637130, ARHR_ALL_HITS: 0.6578925, NOVELTY: 0.0053134, AVERAGE_POPULARITY: 0.6643613, DIVERSITY_MEAN_INTER_LIST: 0.7514149, DIVERSITY_HERFINDAHL: 0.9751360, COVERAGE_ITEM: 0.0207099, COVERAGE_ITEM_CORRECT: 0.0157816, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8626374, DIVERSITY_GINI: 0.0028188, SHANNON_ENTROPY: 6.0016955, RATIO_DIVERSITY_HERFINDAHL: 0.9755013, RATIO_DIVERSITY_GINI: 0.0108243, RATIO_SHANNON_ENTROPY: 0.4820772, RATIO_AVERAGE_POPULARITY: 3.3722154, RATIO_NOVELTY: 0.0313005, 
SearchBayesianSkopt: Config 94 is suboptimal. Config: {'epochs': 92, 'learning_rate': 0.00015083510277684377, 'l2_reg': 1.0038413164333175e-06, 'dropout': 0.6311733583909351, 'total_anneal_steps': 600000, 'anneal_cap': 0.5090683338267985, 'batch_size': 256, 'encoding_size': 173, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2230397, PRECISION_RECALL_MIN_DEN: 0.2247834, RECALL: 0.0499118, MAP: 0.1083791, MAP_MIN_DEN: 0.1093039, MRR: 0.4548027, NDCG: 0.2321567, F1: 0.0815698, HIT_RATE: 0.8921734, ARHR_ALL_HITS: 0.6983324, NOVELTY: 0.0056018, AVERAGE_POPULARITY: 0.5231451, DIVERSITY_MEAN_INTER_LIST: 0.9014295, DIVERSITY_HERFINDAHL: 0.9901363, COVERAGE_ITEM: 0.1065950, COVERAGE_ITEM_CORRECT: 0.0706573, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8910623, DIVERSITY_GINI: 0.0145957, SHANNON_ENTROPY: 8.0382762, RATIO_DIVERSITY_HERFINDAHL: 0.9905072, RATIO_DIVERSITY_GINI: 0.0560478, RATIO_SHANNON_ENTROPY: 0.6456625, RATIO_AVERAGE_POPULARITY: 2.6554196, RATIO_NOVELTY: 0.0329996, 
SearchBayesianSkopt: Config 95 is suboptimal. Config: {'epochs': 19, 'learning_rate': 0.0007321098222908283, 'l2_reg': 0.01, 'dropout': 0.0646186830408255, 'total_anneal_steps': 600000, 'anneal_cap': 0.32404626996607927, 'batch_size': 512, 'encoding_size': 43, 'next_layer_size_multiplier': 7, 'max_n_hidden_layers': 4, 'max_layer_size': 5000.0} - results: PRECISION: 0.2117362, PRECISION_RECALL_MIN_DEN: 0.2132702, RECALL: 0.0459129, MAP: 0.1024704, MAP_MIN_DEN: 0.1033210, MRR: 0.4404194, NDCG: 0.2214664, F1: 0.0754625, HIT_RATE: 0.8733221, ARHR_ALL_HITS: 0.6691365, NOVELTY: 0.0053740, AVERAGE_POPULARITY: 0.6352466, DIVERSITY_MEAN_INTER_LIST: 0.7873173, DIVERSITY_HERFINDAHL: 0.9787260, COVERAGE_ITEM: 0.0322277, COVERAGE_ITEM_CORRECT: 0.0242538, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8722344, DIVERSITY_GINI: 0.0038349, SHANNON_ENTROPY: 6.3667396, RATIO_DIVERSITY_HERFINDAHL: 0.9790926, RATIO_DIVERSITY_GINI: 0.0147260, RATIO_SHANNON_ENTROPY: 0.5113988, RATIO_AVERAGE_POPULARITY: 3.2244328, RATIO_NOVELTY: 0.0316574, 
SearchBayesianSkopt: Config 96 is suboptimal. Config: {'epochs': 83, 'learning_rate': 0.00018978208053839948, 'l2_reg': 1.5564873251565245e-05, 'dropout': 0.09304275253497493, 'total_anneal_steps': 260475, 'anneal_cap': 0.5168024274418908, 'batch_size': 512, 'encoding_size': 1, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1859825, PRECISION_RECALL_MIN_DEN: 0.1873183, RECALL: 0.0390976, MAP: 0.0904489, MAP_MIN_DEN: 0.0912173, MRR: 0.4203459, NDCG: 0.1990596, F1: 0.0646123, HIT_RATE: 0.8254236, ARHR_ALL_HITS: 0.6136163, NOVELTY: 0.0051385, AVERAGE_POPULARITY: 0.7603163, DIVERSITY_MEAN_INTER_LIST: 0.5056873, DIVERSITY_HERFINDAHL: 0.9505650, COVERAGE_ITEM: 0.0021596, COVERAGE_ITEM_CORRECT: 0.0021596, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8243956, DIVERSITY_GINI: 0.0010741, SHANNON_ENTROPY: 4.4656883, RATIO_DIVERSITY_HERFINDAHL: 0.9509211, RATIO_DIVERSITY_GINI: 0.0041245, RATIO_SHANNON_ENTROPY: 0.3586997, RATIO_AVERAGE_POPULARITY: 3.8592711, RATIO_NOVELTY: 0.0302705, 
SearchBayesianSkopt: Config 97 is suboptimal. Config: {'epochs': 79, 'learning_rate': 0.00012978103604863533, 'l2_reg': 0.0007596521478979525, 'dropout': 0.6868215333916499, 'total_anneal_steps': 499157, 'anneal_cap': 0.4164977299131982, 'batch_size': 512, 'encoding_size': 356, 'next_layer_size_multiplier': 8, 'max_n_hidden_layers': 3, 'max_layer_size': 5000.0} - results: PRECISION: 0.2157632, PRECISION_RECALL_MIN_DEN: 0.2173598, RECALL: 0.0472189, MAP: 0.1057412, MAP_MIN_DEN: 0.1065981, MRR: 0.4518282, NDCG: 0.2267040, F1: 0.0774813, HIT_RATE: 0.8793369, ARHR_ALL_HITS: 0.6876933, NOVELTY: 0.0054579, AVERAGE_POPULARITY: 0.5895797, DIVERSITY_MEAN_INTER_LIST: 0.8494383, DIVERSITY_HERFINDAHL: 0.9849376, COVERAGE_ITEM: 0.0452406, COVERAGE_ITEM_CORRECT: 0.0343319, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8782418, DIVERSITY_GINI: 0.0066232, SHANNON_ENTROPY: 7.0707547, RATIO_DIVERSITY_HERFINDAHL: 0.9853066, RATIO_DIVERSITY_GINI: 0.0254334, RATIO_SHANNON_ENTROPY: 0.5679477, RATIO_AVERAGE_POPULARITY: 2.9926334, RATIO_NOVELTY: 0.0321520, 
SearchBayesianSkopt: Config 98 is suboptimal. Config: {'epochs': 23, 'learning_rate': 0.0038795388490078533, 'l2_reg': 0.0005231453570994052, 'dropout': 0.03787353518525611, 'total_anneal_steps': 195549, 'anneal_cap': 0.4831170380440485, 'batch_size': 512, 'encoding_size': 1, 'next_layer_size_multiplier': 2, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.1867601, PRECISION_RECALL_MIN_DEN: 0.1880638, RECALL: 0.0392257, MAP: 0.0908312, MAP_MIN_DEN: 0.0916008, MRR: 0.4224841, NDCG: 0.1999452, F1: 0.0648342, HIT_RATE: 0.8301181, ARHR_ALL_HITS: 0.6165156, NOVELTY: 0.0051763, AVERAGE_POPULARITY: 0.7449865, DIVERSITY_MEAN_INTER_LIST: 0.5303108, DIVERSITY_HERFINDAHL: 0.9530272, COVERAGE_ITEM: 0.0042638, COVERAGE_ITEM_CORRECT: 0.0038762, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8290842, DIVERSITY_GINI: 0.0011537, SHANNON_ENTROPY: 4.6391999, RATIO_DIVERSITY_HERFINDAHL: 0.9533842, RATIO_DIVERSITY_GINI: 0.0044303, RATIO_SHANNON_ENTROPY: 0.3726368, RATIO_AVERAGE_POPULARITY: 3.7814591, RATIO_NOVELTY: 0.0304928, 
SearchBayesianSkopt: Config 99 is suboptimal. Config: {'epochs': 37, 'learning_rate': 0.0038753878932186007, 'l2_reg': 3.622724437272595e-05, 'dropout': 0.03797488387031527, 'total_anneal_steps': 137630, 'anneal_cap': 0.18800151168972526, 'batch_size': 512, 'encoding_size': 31, 'next_layer_size_multiplier': 5, 'max_n_hidden_layers': 1, 'max_layer_size': 5000.0} - results: PRECISION: 0.2135553, PRECISION_RECALL_MIN_DEN: 0.2149839, RECALL: 0.0454580, MAP: 0.1045561, MAP_MIN_DEN: 0.1053643, MRR: 0.4454434, NDCG: 0.2241852, F1: 0.0749598, HIT_RATE: 0.8711215, ARHR_ALL_HITS: 0.6796599, NOVELTY: 0.0052667, AVERAGE_POPULARITY: 0.6897695, DIVERSITY_MEAN_INTER_LIST: 0.7071954, DIVERSITY_HERFINDAHL: 0.9707144, COVERAGE_ITEM: 0.0449637, COVERAGE_ITEM_CORRECT: 0.0282961, COVERAGE_USER: 0.9987546, COVERAGE_USER_CORRECT: 0.8700366, DIVERSITY_GINI: 0.0030734, SHANNON_ENTROPY: 5.8715632, RATIO_DIVERSITY_HERFINDAHL: 0.9710780, RATIO_DIVERSITY_GINI: 0.0118021, RATIO_SHANNON_ENTROPY: 0.4716245, RATIO_AVERAGE_POPULARITY: 3.5011843, RATIO_NOVELTY: 0.0310254, 
SearchBayesianSkopt: Search complete. Best config is 49: {'epochs': 26, 'learning_rate': 0.0008692067143251014, 'l2_reg': 0.001528399179340595, 'dropout': 0.6305206323644355, 'total_anneal_steps': 554864, 'anneal_cap': 0.3659360905307019, 'batch_size': 128, 'encoding_size': 442, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0}
SearchBayesianSkopt: Best config evaluated with evaluator_test with constructor data for final test. Config: {'epochs': 26, 'learning_rate': 0.0008692067143251014, 'l2_reg': 0.001528399179340595, 'dropout': 0.6305206323644355, 'total_anneal_steps': 554864, 'anneal_cap': 0.3659360905307019, 'batch_size': 128, 'encoding_size': 442, 'next_layer_size_multiplier': 10, 'max_n_hidden_layers': 2, 'max_layer_size': 5000.0} - results:
CUTOFF: 10 - PRECISION: 0.3727146, PRECISION_RECALL_MIN_DEN: 0.3742627, RECALL: 0.0664328, MAP: 0.2256050, MAP_MIN_DEN: 0.2263863, MRR: 0.6227837, NDCG: 0.3869596, F1: 0.1127661, HIT_RATE: 0.9646653, ARHR_ALL_HITS: 1.1657979, NOVELTY: 0.0057391, AVERAGE_POPULARITY: 0.4675317, DIVERSITY_MEAN_INTER_LIST: 0.9409354, DIVERSITY_HERFINDAHL: 0.9940866, COVERAGE_ITEM: 0.1543829, COVERAGE_ITEM_CORRECT: 0.1139598, COVERAGE_USER: 0.9993407, COVERAGE_USER_CORRECT: 0.9640293, DIVERSITY_GINI: 0.0258897, SHANNON_ENTROPY: 8.8850832, RATIO_DIVERSITY_HERFINDAHL: 0.9944673, RATIO_DIVERSITY_GINI: 0.1031116, RATIO_SHANNON_ENTROPY: 0.7162263, RATIO_AVERAGE_POPULARITY: 2.3150306, RATIO_NOVELTY: 0.0270770, 

